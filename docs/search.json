[
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html",
    "href": "posts/study/2023-10-10-07.  summary (1).html",
    "title": "07. summary (1)",
    "section": "",
    "text": "cd /content/drive/MyDrive/Colab Notebooks/ISLP/\n\n/content/drive/MyDrive/Colab Notebooks/ISLP",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html#활성화-함수-activation",
    "href": "posts/study/2023-10-10-07.  summary (1).html#활성화-함수-activation",
    "title": "07. summary (1)",
    "section": "2-1. 활성화 함수 (activation)",
    "text": "2-1. 활성화 함수 (activation)\n- 활성화함수란 : 은닉층 각각의 노드에서 입력한 데이터를 비선형으로 바꾸어주는 역할을 한다.\n\npiecewise-regreesion\n- 예를 들어 아래와 같은 함수 형태꼴이 있다고 하자.\n\\[y = \\begin {cases} x + 0.3\\varepsilon, & x \\leq 0 \\\\ 3.5 + 0.3\\varepsilon, & x &gt; 0 \\end {cases}\\]\n\nx = np.linspace(-1, 1, 1000)\ne = np.random.normal(size=1000)\n\ny = list(map(lambda x,e : x + 0.3*e if x&lt;=0 else 3.5*x +0.3*e,x,e))\ny = np.array(y)\n\n\n\nCode\nplt.figure(figsize = (10, 4))\nplt.plot(x[x&lt;=0], y[x&lt;=0], \".\",  label = r\"$(x \\leq 0)$\", alpha = 0.4)\nplt.plot(x[x&gt;0], y[x&gt;0], \".\",  label = r\"$(x &gt; 0)$\",alpha = 0.3)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n- 일단 기존의 선형함수를 적합한 layer를 확인\n\n## 1. 선형함수\nmodel1= Sequential()\nl1 = Dense(1, input_shape =(1,))\nmodel1.add(l1)\nmodel1.compile(tf.optimizers.SGD(0.1),loss = \"mse\")\nmodel1.fit(x, y, epochs = 100, verbose = 0)\n\n&lt;keras.src.callbacks.History at 0x79e904232860&gt;\n\n\n\nyhat1 = model1.predict(x)\n\n32/32 [==============================] - 0s 1ms/step\n\n\n\n\nCode\nplt.figure(figsize = (10, 4))\nplt.plot(x[x&lt;=0], y[x&lt;=0], \".\",  label = r\"$(x \\leq 0)$\", alpha = 0.4)\nplt.plot(x[x&gt;0], y[x&gt;0], \".\",  label = r\"$(x &gt; 0)$\",alpha = 0.3)\nplt.plot(x,yhat1, \".\",  label = r\"$(x, \\hat {y})$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n- 위의 적합된 모형은 꺽은선이 아닌 선형으로 모델이 적합되었으므로 틀렸음\n- 해결법\n\n일단 선형 레이어를 추가\n비선형 활성화 함수를 가지는 레이러를 추가\n그다음 그것들을 다시 선형 레이어에 태우면 해결할 수 있지 않나??\n\n\n\nSigmoid vs relu\n\n## 1. Sigmoid\nmodel1= Sequential()\nl1 = Dense(2, input_shape = (1,))\ns1 = Dense(1, input_shape =(2,), activation = \"sigmoid\")\nl2  = Dense(1, input_shape = (2,))\n\nmodel1.add(l1)\nmodel1.add(s1)\nmodel1.add(l2)\n\nmodel1.compile(tf.optimizers.SGD(0.1),loss = \"mse\")\nmodel1.fit(x, y, epochs = 100, verbose = 0)\n\n## 2. relu\nmodel2= Sequential()\n\nl1 = Dense(2, input_shape = (1,))\na1 = Dense(1, input_shape =(1,), activation = \"relu\")\nl2  = Dense(1, input_shape = (2,))\n\nmodel2.add(l1)\nmodel2.add(a1)\nmodel2.add(Dense(1))\nmodel2.compile(tf.optimizers.SGD(0.1),loss = \"mse\")\nmodel2.fit(x, y, epochs = 100, verbose = 0)\n\n&lt;keras.src.callbacks.History at 0x79e88a1ee7a0&gt;\n\n\n\nsig_hat = model1.predict(x)\nrelu_hat = model2.predict(x)\n\n32/32 [==============================] - 0s 2ms/step\n32/32 [==============================] - 0s 2ms/step\n\n\n\n\nCode\nfig, axes = plt.subplots(1,2, figsize = (10, 4))\nax1, ax2 = axes\n\nax1.plot(x[x&lt;=0], y[x&lt;=0], \".\",  label = r\"$(x \\leq 0)$\", alpha = 0.4)\nax1.plot(x[x&gt;0], y[x&gt;0], \".\",  label = r\"$(x &gt; 0)$\",alpha = 0.3)\nax1.plot(x,sig_hat, \".r\",  label = r\"$(x, \\hat {y}_{sigmoid})$\")\nax1.legend()\n\nax2.plot(x[x&lt;=0], y[x&lt;=0], \".\",  label = r\"$(x \\leq 0)$\", alpha = 0.4)\nax2.plot(x[x&gt;0], y[x&gt;0], \".\",  label = r\"$(x &gt; 0)$\",alpha = 0.3)\nax2.plot(x,relu_hat, \".g\",  label = r\"$(x, \\hat {y}_{relu})$\")\nax2.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n- 앞서 언급한 해결법\n\n일단 선형 레이어를 추가\n비선형 활성화 함수를 가지는 레이어를 추가\n그다음 그것들을 다시 선형 레이어에 태우면 해결할 수 있지 않나??\n\n- relu 함수 고찰\n\nrelu함수를 쓰는 이유는 sigmoid 함수의 기울기 소실 문제 때문이다.\n\n\\[\\frac{dy} {dx} = y(1-y) \\]\n\\[w_t = w_{t-1} + \\alpha \\frac {\\partial loss}{\\partial w_{t+1\n}}\\times y(1-y)\\]\n\n기울기 소실이란 역전파과정에서 은닉층이 깊어질수록 역전파 되는 값이 0으로 수렴하는 것이다.\n그런데 시그모이드 함수의 기울기는 0 ~ 0.25의 값을 가지므로 \\(t\\)값이 증가할 수록 역전파시 값이 전달되는 값이 적어져 결국 파라미터 업데이트가 안 되는 상황이 발생한다.\n그래서 나온게 입력값 중 0이하의 값은 모두 0으로 처리하고 그 외의 값은 그대로 출력하는 relu함수가 등장했다.\n\nrelu함수의 기울기, 미분 값은 항상 0 아니면 1이므로 기울기 소실 문제가 발생할 일이 없지 않은가?\n\n그러나 항상 옳은 것은 아님… 위처럼 단순한 piece-wiseresssion 문제에서는 오히려 sigmoid가 더 좋을 수 있음\n\n- 근데, 대부분에선 relu가 더 좋은 성능을 발휘하고 우리는 실제로 그런 상황에 맞닥뜨릴 때니 누가 물어보면 이렇게 대답하자\n\n기울기 소실 문제 때문에 relu를 씁니다.\nsigmoid 함수는 미분한 기울기 값이 0~0.25값을 가져 역전파시 업데이트할 정보가 전달되지 않는 기울기 소실문제가 발생해서 relu를 씁니다.",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html#손실함수-loss",
    "href": "posts/study/2023-10-10-07.  summary (1).html#손실함수-loss",
    "title": "07. summary (1)",
    "section": "2-2. 손실함수 (loss)",
    "text": "2-2. 손실함수 (loss)\n\nMSE\n\\[\\text{MSE} = \\frac {1}{n}\\sum_{i=1}^{n}(y-\\hat y)^2\\]\n\n\ncross-entropy\n\\[\\text {Entropy} = - \\sum_{i=1}^{m}  y_i\\log_2 \\hat {y}_i\\]",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html#최적화-optimizer",
    "href": "posts/study/2023-10-10-07.  summary (1).html#최적화-optimizer",
    "title": "07. summary (1)",
    "section": "2-3. 최적화 (optimizer)",
    "text": "2-3. 최적화 (optimizer)\n- 음 이부분은 강사님이 말씀하신대로 review를 너무 잘해놓으셔서 그것만 보시면됩니다.\n\n개인적인 경험 1 : 수식 다적어가서 교수님 앞에서 발표했다가 뭐하는 거냐고 혼난적 있어요….\n개인적인 경험 2 : 실제로 adam하고 여러개 비교해봐서 돌려봤는데 adam이 최고입니다. 궁금하시면 수식 뜯어보세요. (산디과 아니면 추천드리지 않습니다.)\n\n- 요약하자면\n\nAdam이란 옵티마이저는 저희가 추정하는 모델의 가중치가 loss function에서 로컬 미니멈에 빠지는 것을 그때 그떄 상황에 맞게 알아서 잘 조절해가며 요리조리 잘 피해 최적의 가중치를 찾아주는 겁니당",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html#import",
    "href": "posts/study/2023-10-10-07.  summary (1).html#import",
    "title": "07. summary (1)",
    "section": "import",
    "text": "import\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random as rd\nimport cv2, os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\nfrom keras.backend import clear_session\nfrom keras.optimizers import Adam\nfrom keras.datasets import mnist, fashion_mnist\n\nimport tensorflow as tf\nimport tensorflow.experimental.numpy as tnp\ntnp.experimental_enable_numpy_behavior()\n\n\n\n모델1\n\n\n\n\nLayer (type)\nOutput Shape\nParam #\n\n\n\n\nconv2d (Conv2D)\n(None, 28, 28, 16)\n160\n\n\nmax_pooling2d\n(None, 14, 14, 16)\n0\n\n\nflatten (Flatten)\n(None, 3136)\n0\n\n\ndense (Dense)\n(None, 128)\n401536\n\n\ndense_1 (Dense)\n(None, 10)\n1290\n\n\n\n\n모델2\n\n\n\n\nLayer (type)\nOutput Shape\nParam #\n\n\n\n\nconv2d (Conv2D)\n(None, 28, 28, 32)\n320\n\n\nmax_pooling2d\n(None, 14, 14, 32)\n0\n\n\nflatten (Flatten)\n(None, 6272)\n0\n\n\ndense (Dense)\n(None, 128)\n802944\n\n\ndense_1 (Dense)\n(None, 10)\n1290",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html#데이터-이해-및-전처리",
    "href": "posts/study/2023-10-10-07.  summary (1).html#데이터-이해-및-전처리",
    "title": "07. summary (1)",
    "section": "데이터 이해 및 전처리",
    "text": "데이터 이해 및 전처리\n\n(x_train, y_train), (x_val, y_val) = mnist.load_data()\n\n\nx_train = x_train/255\nx_val = x_val/255",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html#각각-모델링",
    "href": "posts/study/2023-10-10-07.  summary (1).html#각각-모델링",
    "title": "07. summary (1)",
    "section": "각각 모델링",
    "text": "각각 모델링\n\nmodel1 = Sequential([Conv2D(16, kernel_size=(3, 3), input_shape=(28, 28, 1), padding='same', strides = 1, activation=\"relu\"  ),\n                    MaxPooling2D(pool_size=(2, 2), strides=2),\n                    Flatten(),\n                    Dense( 128, activation = \"relu\"),\n                    Dense(10, activation = \"softmax\" )\n])\n\nmodel1.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')\n\nmodel2 = Sequential([ Conv2D(32, kernel_size  =(3, 3), input_shape = (28, 28, 1), padding='same', strides = 1, activation = \"relu\"  ),\n                     MaxPooling2D(pool_size =(2, 2), strides=2),\n                     Flatten (),\n                     Dense(128, activation = \"relu\" ),\n                     Dense(10, activation= \"softmax\")\n])\n\nmodel2.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')\n\n\nh1 = model1.fit(x_train, y_train, epochs = 10, validation_split=0.2, verbose = 0).history\nh2 = model2.fit(x_train, y_train, epochs = 10, validation_split=0.2, verbose = 0).history",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html#model-save",
    "href": "posts/study/2023-10-10-07.  summary (1).html#model-save",
    "title": "07. summary (1)",
    "section": "model save",
    "text": "model save\n- 이것 떄문에 드라이브 마운트 하는 거에요. 안하면 런타임 끊길경우 모델링 다시 수행해야합니다.\n\nmodel1.save(\"mode1.h5\")\nmodel2.save(\"mode2.h5\")",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-10-10-07.  summary (1).html#model-load",
    "href": "posts/study/2023-10-10-07.  summary (1).html#model-load",
    "title": "07. summary (1)",
    "section": "model load",
    "text": "model load\n\nfrom keras.models import load_model\n\nm1 = load_model(\"mode1.h5\")\nm2 = load_model(\"mode2.h5\")\n\n\n예측\n\npred1 = m1.predict(x_val).argmax(axis = 1)\npred2 = m2.predict(x_val).argmax(axis = 1)\n\n313/313 [==============================] - 1s 3ms/step\n313/313 [==============================] - 1s 3ms/step\n\n\n\n\n각 예측성능 지표 저장\n\n\nCode\nacc = accuracy_score(y_val,pred1)\npre = precision_score(y_val,pred1, average = \"macro\")\nre = recall_score(y_val,pred1, average = \"macro\")\nf1 = f1_score(y_val,pred1, average = \"macro\")\ndf1 = pd.DataFrame([acc,pre,re,f1])\ndf1[\"model\"] = \"model1\"\ndf1[\"measure\"] = [\"accuracy\", \"precision\", \"recall\", \"F1_score\"]\ndf1= df1.rename(columns = {0 : \"value\"})\n\n\nacc = accuracy_score(y_val,pred2)\npre = precision_score(y_val,pred2, average = \"macro\")\nre = recall_score(y_val,pred2, average = \"macro\")\nf1 = f1_score(y_val,pred2, average = \"macro\")\ndf2 = pd.DataFrame([acc,pre,re,f1])\ndf2[\"model\"] = \"model2\"\ndf2[\"measure\"] = [\"accuracy\", \"precision\", \"recall\", \"F1_score\"]\ndf2= df2.rename(columns = {0 : \"value\"})\n\ntotal1 = pd.concat([df1,df2],axis = 0)\ntotal1\n\n\n\n\n  \n    \n\n\n\n\n\n\nvalue\nmodel\nmeasure\n\n\n\n\n0\n0.984400\nmodel1\naccuracy\n\n\n1\n0.984280\nmodel1\nprecision\n\n\n2\n0.984329\nmodel1\nrecall\n\n\n3\n0.984253\nmodel1\nF1_score\n\n\n0\n0.983100\nmodel2\naccuracy\n\n\n1\n0.983138\nmodel2\nprecision\n\n\n2\n0.982968\nmodel2\nrecall\n\n\n3\n0.982984\nmodel2\nF1_score\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n\n예제1. net + matploltlib\n\n시각화 1. fig + axes\n\n# code-fold : true\nfig, axes = plt.subplots(1,2, figsize = (12, 4)) # step 1. 도화지 선언\n\nax1, ax2 = axes ## step 2. 각 축의 이름 선언\n\nbar_colors = ['red', 'blue', 'green', 'orange']\nbar_labels = ['accuracy', 'precision', \"recall\", 'F1_score']\nax1.bar(df1[\"measure\"], df1[\"value\"], label=bar_labels, color=bar_colors)\nax1.set_title(\"model1 evaluate\")\nax1.legend()\n\nax2.bar(df2[\"measure\"], df2[\"value\"], label=bar_labels, color=bar_colors)\nax2.set_title(\"model2 evaluate\")\nax2.legend()\n\nfig.tight_layout()\nfig.show()\n\n\n\n\n\n\n\n\n\n\n시각화 2. fig + loof : 별로 추천안함..\n\n# code-fold : true\nfig, axes = plt.subplots(1,2, figsize = (12, 4)) # step 1. 도화지 선언\n\n\nbar_colors = ['red', 'blue', 'green', 'orange']\nbar_labels = ['accuracy', 'precision', \"recall\", 'F1_score']\nt = [\"model1 evaluate\", \"model2 evaluate\"]\nfor i in range(1,3) :\n      exec(f'axes[{i-1}].bar(df{i}[\"measure\"], df{i}[\"value\"], label=bar_labels, color=bar_colors)')\n      axes[i-1].set_title(t[i-1])\n      axes[i-1].legend()\n\nfig.tight_layout()\nfig.show()\n\n\n\n\n\n\n\n\n\n\n\n예제2. net + matploltlib + seaborn\n\ntotal1\n\n\n\n  \n    \n\n\n\n\n\n\nvalue\nmodel\nmeasure\n\n\n\n\n0\n0.984400\nmodel1\naccuracy\n\n\n1\n0.984280\nmodel1\nprecision\n\n\n2\n0.984329\nmodel1\nrecall\n\n\n3\n0.984253\nmodel1\nF1_score\n\n\n0\n0.983100\nmodel2\naccuracy\n\n\n1\n0.983138\nmodel2\nprecision\n\n\n2\n0.982968\nmodel2\nrecall\n\n\n3\n0.982984\nmodel2\nF1_score\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nfig, axes = plt.subplots(1,2, figsize = (12, 4)) # step 1. 도화지 선언\n\nsns.barplot(x = df1[\"measure\"], y = df1[\"value\"],\n                    hue = df1[\"measure\"], ax = axes[0])\naxes[0].set_title(\"model1 evaluate\")\n\nsns.barplot(x = df2[\"measure\"], y = df2[\"value\"],\n                    hue = df2[\"measure\"], ax = axes[1])\naxes[1].set_title(\"model2 evaluate\")\n\nfig.tight_layout()\nfig.show()\n\n\n\n\n\n\n\n\n\n\n예제3. net + plotly\n\ntotal1\n\n\n\n  \n    \n\n\n\n\n\n\nvalue\nmodel\nmeasure\n\n\n\n\n0\n0.984400\nmodel1\naccuracy\n\n\n1\n0.984280\nmodel1\nprecision\n\n\n2\n0.984329\nmodel1\nrecall\n\n\n3\n0.984253\nmodel1\nF1_score\n\n\n0\n0.983100\nmodel2\naccuracy\n\n\n1\n0.983138\nmodel2\nprecision\n\n\n2\n0.982968\nmodel2\nrecall\n\n\n3\n0.982984\nmodel2\nF1_score\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n- 파라미터 요약\n\nx, y : 위에 tidydata에서 표시할 값들\ncolor : 색깔을 표시할 변수\nfacet_col : subplots을 표시할 변수\nkind : 사용할 chart의 종류\nbackend : backend 연산을 해서 그래프를 만들 때 어떤 그래프를 사용할 것인가??\n\n\ntotal1.plot(x = \"measure\", y =\"value\",\n                    color = \"measure\", facet_col = \"model\",\n                  kind = \"bar\", backend = \"plotly\", width = 500 , height = 500, opacity = 0.5 )",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "07. summary (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-09-26-05. net 설계 (1).html",
    "href": "posts/study/2023-09-26-05. net 설계 (1).html",
    "title": "05. net 설계 (1)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-zueMdNhXiDTIMD-Dz5sbBD\n\n\n\nimports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.experimental.numpy as tnp\n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n\n\n\\(x \\to \\hat{y}\\) 가 되는 과정을 그림으로 그리기\n- 단순회귀분석의 예시 - \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i, \\quad i=1,2,\\dots,n\\)\n(표현1)\n\n#collapse\ngv('''\n    \"1\" -&gt; \"β̂₀ + xₙ*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"xₙ\" -&gt; \"β̂₀ + xₙ*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + xₙ*β̂₁,    bias=False\" -&gt; \"ŷₙ\"[label=\"identity\"]\n\n    \".\" -&gt; \"....................................\"[label=\"* β̂₀\"]\n    \"..\" -&gt; \"....................................\"[label=\"* β̂₁\"]\n    \"....................................\" -&gt; \"...\"[label=\" \"]\n\n    \"1 \" -&gt; \"β̂₀ + x₂*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x₂\" -&gt; \"β̂₀ + x₂*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x₂*β̂₁,    bias=False\" -&gt; \"ŷ₂\"[label=\"identity\"]\n\n    \"1  \" -&gt; \"β̂₀ + x₁*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x₁\" -&gt; \"β̂₀ + x₁*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x₁*β̂₁,    bias=False\" -&gt; \"ŷ₁\"[label=\"identity\"]\n''')\n\n\n\n\n\n\n\n\n- 표현1의 소감? - 교수님이 고생해서 만든것 같음 - 그런데 그냥 다 똑같은 그림의 반복이라 사실 고생한 의미가 없음.\n(표현2)\n- 그냥 아래와 같이 그리고 “모든 \\(i=1,2,3,\\dots,n\\)에 대하여 \\(\\hat{y}_i\\)을 아래의 그림과 같이 그린다”고 하면 될것 같다.\n\n#collapse\ngv('''\n    \"1\" -&gt; \"β̂₀ + xᵢ*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"xᵢ\" -&gt; \"β̂₀ + xᵢ*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + xᵢ*β̂₁,    bias=False\" -&gt; \"ŷᵢ\"[label=\"identity\"]\n\n''')\n\n\n\n\n\n\n\n\n(표현3)\n- 그런데 “모든 \\(i=1,2,3,\\dots,n\\)에 대하여 \\(\\hat{y}_i\\)을 아래의 그림과 같이 그린다” 라는 언급자체도 반복할 필요가 없을 것 같다. (어차피 당연히 그럴테니까) 그래서 단순히 아래와 같이 그려도 무방할듯 하다.\n\ngv('''\n    \"1\" -&gt; \"β̂₀ + x*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x\" -&gt; \"β̂₀ + x*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x*β̂₁,    bias=False\" -&gt; \"ŷ\"[label=\"identity\"]\n\n''')\n\n\n\n\n\n\n\n\n(표현4)\n- 위의 모델은 아래와 같이 쓸 수 있다. (\\(\\beta_0\\)를 바이어스로 표현)\n\n#collapse\ngv('''\n\"x\" -&gt; \"x*β̂₁,    bias=True\"[label=\"*β̂₁\"] ;\n\"x*β̂₁,    bias=True\" -&gt; \"ŷ\"[label=\"indentity\"] ''')\n\n\n\n\n\n\n\n\n\n실제로는 이 표현을 많이 사용함\n\n(표현5)\n- 벡터버전으로 표현하면 아래와 같다. 이 경우에는 \\({\\bf X}=[1,x]\\)에 포함된 1이 bias의 역할을 해주므로 bias = False 임.\n\n#collapse\ngv('''\n\"X\" -&gt; \"X@β̂,    bias=False\"[label=\"@β̂\"] ;\n\"X@β̂,    bias=False\" -&gt; \"ŷ\"[label=\"indentity\"] ''')\n\n\n\n\n\n\n\n\n\n저는 이걸 좋아해요\n\n(표현5)’\n- 딥러닝에서는 \\(\\hat{\\boldsymbol{\\beta}}\\) 대신에 \\(\\hat{{\\bf W}}\\)을 라고 표현한다.\n\n#collapse\ngv('''\n\"X\" -&gt; \"X@Ŵ,    bias=False\"[label=\"@Ŵ\"] ;\n\"X@Ŵ,    bias=False\" -&gt; \"ŷ\"[label=\"identity\"] ''')\n\n\n\n\n\n\n\n\n- 실제로는 표현4 혹은 표현5를 외우면 된다.\n\n\nLayer의 개념\n- (표현4) 혹은 (표현5)의 그림은 레이어로 설명할 수 있다.\n- 레이어는 항상 아래와 같은 규칙을 가진다. - 첫 동그라미는 레이어의 입력이다. - 첫번째 화살표는 선형변환을 의미한다. - 두번째 동그라미는 선형변환의 결과이다. (이때 bias가 false인지 true인지에 따라서 실제 수식이 조금 다름) - 두번째 화살표는 두번째 동그라미에 어떠한 함수 \\(f\\)를 취하는 과정을 의미한다. (우리의 그림에서는 \\(f(x)=x\\)) - 세번째 동그라미는 레이어의 최종출력이다.\n- 엄청 복잡한데, 결국 레이어를 만들때 위의 그림들을 의미하도록 하려면 아래의 4개의 요소만 필요하다. 1. 레이어의 입력차원 2. 선형변환의 결과로 얻어지는 차원 3. 선형변환에서 바이어스를 쓸지? 안쓸지? 4. 함수 \\(f\\)\n- 주목: 1,2가 결정되면 자동으로 \\(\\hat{{\\bf W}}\\)의 차원이 결정된다.\n(예시) - 레이어의 입력차원=2, 선형변환의 결과로 얻어지는 차원=1: \\(\\hat{\\bf W}\\)는 (2,1) 매트릭스 &gt; (1,2) @ (2,1) = (1,1) - 레이어의 입력차원=20, 선형변환의 결과로 얻어지는 차원=5: \\(\\hat{\\bf W}\\)는 (20,5) 매트릭스 - 레이어의 입력차원=2, 선형변환의 결과로 얻어지는 차원=50: \\(\\hat{\\bf W}\\)는 (2,50) 매트릭스\n- 주목2: 이중에서 절대 생략불가능 것은 “2. 선형변환의 결과로 얻어지는 차원” 이다. - 레이어의 입력차원: 실제 레이어에 데이터가 들어올 때 데이터의 입력차원을 컴퓨터 스스로 체크하여 \\(\\hat{\\bf W}\\)의 차원을 결정할 수 있음. - 바이어스를 쓸지? 안쓸지? 기본적으로 쓴다고 가정한다. - 함수 \\(f\\): 기본적으로 항등함수를 가정하면 된다.\n\n\nKeras를 이용한 풀이\n- 기본뼈대: net생성 \\(\\to\\) add(layer) \\(\\to\\) compile(opt,loss) \\(\\to\\) fit(data,epochs)\n- 데이터정리\n\\[{\\bf y}\\approx 2.5 +4*x\\]\n\ntnp.random.seed(43052)\nN= 200\nx= tnp.linspace(0,1,N)\nepsilon= tnp.random.randn(N)*0.5\ny= 2.5+4*x +epsilon\n\n\nX=tf.stack([tf.ones(N,dtype='float64'),x],axis=1)\n\n\n풀이1: 스칼라버전\n(0단계) 데이터정리\n\ny=y.reshape(N,1)  #차원 맞춰줘야됨\nx=x.reshape(N,1)\nx.shape,y.shape\n\n(TensorShape([200, 1]), TensorShape([200, 1]))\n\n\n(1단계) net 생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1)\n# 입력차원? 데이터를 넣어보고 결정, 바이어스=디폴드값을 쓰겠음 (use_bias=true), 함수도 디폴트값을 쓰겠음 (f(x)=x)\nnet.add(layer)\n\n(3단계) net.compile(opt,loss_fn)\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.keras.losses.MSE)\n\n(4단계) net.fit(x,y,epochs)\n\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) # batch_size=N 일 경우에 경사하강법이 적용, batch_size!=N 이면 확률적 경사하강법 적용\n\n&lt;keras.src.callbacks.History at 0x7ef5af8cac50&gt;\n\n\n(결과확인)\n\nnet.weights\n\n[&lt;tf.Variable 'dense_10/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.9330256]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_10/bias:0' shape=(1,) dtype=float32, numpy=array([2.583672], dtype=float32)&gt;]\n\n\n\n\n풀이2: 벡터버전\n(0단계) 데이터정리\n\nX.shape,y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net 생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False)\nnet.add(layer)\n\n(3단계) net.compile(opt,loss_fn)\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.keras.losses.MSE)\n\n(4단계) net.fit(x,y,epochs)\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) # batch_size=N 일 경우에 경사하강법이 적용, batch_size!=N 이면 확률적 경사하강법 적용\n\n&lt;keras.src.callbacks.History at 0x7ef5af966260&gt;\n\n\n(결과확인)\n\nnet.weights\n\n[&lt;tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)&gt;]\n\n\n\n\n잠시문법정리\n- 잠깐 Dense layer를 만드는 코드를 정리해보자.\n\ntf.keras.layers.Dense?\n\n\n아래는 모두 같은 코드이다.\n\n\ntf.keras.layers.Dense(1)\ntf.keras.layers.Dense(units=1)\ntf.keras.layers.Dense(units=1,activation=‘linear’) // identity 가 더 맞는것 같은데..\ntf.keras.layers.Dense(units=1,activation=‘linear’,use_bias=True)\n\n\n아래의 코드1,2는 (1)의 코드들과 살짝 다른코드이다. (코드1과 코드2는 같은코드임)\n\n\ntf.keras.layers.Dense(1,input_dim=2) # 코드1\ntf.keras.layers.Dense(1,input_shape=(2,)) # 코드2\n\n\n아래는 사용불가능한 코드이다.\n\n\ntf.keras.layers.Dense(1,input_dim=(2,)) # 코드1\ntf.keras.layers.Dense(1,input_shape=2) # 코드2\n\n\nimport numpy as np\nnp.array([1,2,3]).shape\n\n(3,)\n\n\n- 왜 input_dim이 필요한가?\n\nnet1 = tf.keras.Sequential()\nnet1.add(tf.keras.layers.Dense(1,use_bias=False))\n\n\nnet2 = tf.keras.Sequential()\nnet2.add(tf.keras.layers.Dense(1,use_bias=False,input_dim=2))\n\n\n#net1.weights     #입력 차원 제공되지 않아 가중치 초기화가 불가능.\n\nValueError: ignored\n\n\n\nnet2.weights\n\n[&lt;tf.Variable 'dense_13/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[-1.2667724],\n        [-1.3087405]], dtype=float32)&gt;]\n\n\n\n#net1.summary()\n\nValueError: ignored\n\n\n\nnet2.summary()\n\nModel: \"sequential_13\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_13 (Dense)            (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2 (8.00 Byte)\nTrainable params: 2 (8.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\n\n풀이3: 스칼라버전, 임의의 초기값을 설정\n(0단계) 데이터정리\n\ny=y.reshape(N,1)\nx=x.reshape(N,1)\nx.shape,y.shape\n\n(TensorShape([200, 1]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,input_dim=1)\n\n\nnet.add(layer)\n\n\n초기값을 설정\n\nnet.weights\n\n[&lt;tf.Variable 'dense_14/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.6367081]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_14/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&gt;]\n\n\n\nnet.get_weights()\n\n[array([[1.6367081]], dtype=float32), array([0.], dtype=float32)]\n\n\n\nweight=1.2, bias=0순으로 출력\n\n\nnet.set_weights?\n\n\nlayer_b.set_weights(layer_a.get_weights()) 와 같은방식으로 쓴다는 것이군?\n\n- 한번따라해보자.\n\n_w = net.get_weights()\n_w\n\n[array([[1.6367081]], dtype=float32), array([0.], dtype=float32)]\n\n\n\n_w[0]\n\narray([[1.6367081]], dtype=float32)\n\n\n\n_w[1]\n\narray([0.], dtype=float32)\n\n\n\n길이가 2인 리스트이고, 각 원소는 numpy array 임\n\n\nnet.set_weights(\n    [np.array([[10.0]],dtype=np.float32), # weight, β1_hat\n     np.array([-5.0],dtype=np.float32)] # bias, β0_hat\n)\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense_14/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[10.]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_14/bias:0' shape=(1,) dtype=float32, numpy=array([-5.], dtype=float32)&gt;]\n\n\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1),tf.losses.MSE)\n\n(4단계) net.fit()\n\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n&lt;keras.src.callbacks.History at 0x7ef5b359ce20&gt;\n\n\n결과확인\n\nnet.weights\n\n[&lt;tf.Variable 'dense_14/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.933048]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_14/bias:0' shape=(1,) dtype=float32, numpy=array([2.58366], dtype=float32)&gt;]\n\n\n\n\n풀이4: 벡터버전, 임의의 초기값을 설정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False,input_dim=2)\n\n\nnet.add(layer)\n\n\n초기값을 설정하자\n\nnet.set_weights([np.array([[ -5.0],[10.0]], dtype=np.float32)])\n\n\nnet.get_weights()\n\n[array([[-5.],\n        [10.]], dtype=float32)]\n\n\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.losses.MSE)\n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N)\n\n&lt;keras.src.callbacks.History at 0x7ef5b34ece80&gt;\n\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense_15/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.58366 ],\n        [3.933048]], dtype=float32)&gt;]\n\n\n- 사실 실전에서는 초기값을 설정할 필요가 별로 없음.\n\n\n풀이5: 벡터버전 사용자정의 손실함수\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False)\n\n\nnet.add(layer)\n\n(3단계) net.compile()\n\nloss_fn = lambda y,yhat: (y-yhat).T @ (y-yhat) / N\n\n\nnet.compile(tf.keras.optimizers.SGD(0.1), loss_fn)\n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N)\n\n&lt;keras.src.callbacks.History at 0x7ef5b3346f80&gt;\n\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense_16/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)&gt;]\n\n\n\n\n풀이6: 벡터버전, net.compile의 옵션으로 손실함수 지정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nnet.add(tf.keras.layers.Dense(1,use_bias=False))\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1), loss='mse')\n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N)\n\n&lt;keras.src.callbacks.History at 0x7ef5b313c040&gt;\n\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense_17/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)&gt;]\n\n\n\n\n풀이7: 벡터버전, net.compile의 옵션으로 손실함수 지정 + 옵티마이저 지정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nnet.add(tf.keras.layers.Dense(1,use_bias=False))\n\n(3단계) net.compile()\n\nnet.compile(optimizer='sgd', loss='mse')\n#net.optimizer.lr = tf.Variable(0.1,dtype=tf.float32)\n#net.optimizer.lr = 0.1\n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=5000,verbose=0,batch_size=N)    #epochs 늘리면 됨\n\n&lt;keras.src.callbacks.History at 0x7ef5b3192380&gt;\n\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense_18/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5841591],\n        [3.932113 ]], dtype=float32)&gt;]\n\n\n\n\n\n여러가지 회귀모형의 적합과 학습과정의 모니터링\n\n예제1\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 x_i\\)\n\nnp.random.seed(43052)\nN= 100\nx= np.random.randn(N)\nepsilon = np.random.randn(N)*0.5\ny= 2.5+4*x +epsilon\n\n\nX= np.stack([np.ones(N),x],axis=1)\ny= y.reshape(N,1)\n\n\nX[:3]\n\narray([[1.        , 0.38342049],\n       [1.        , 1.0841745 ],\n       [1.        , 1.14277825]])\n\n\n\nplt.plot(x,y,'o') # 관측한 자료\n\n\n\n\n\n\n\n\n\nbeta_hat = np.array([-3,-2]).reshape(2,1)\n\n\nyhat = X@beta_hat\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.reshape(-1),'-')\n\n\n\n\n\n\n\n\n더 좋은 적합선을 얻기위해서! loss함수 최소되는 선을 찾으면 되지 않을까??\n\nslope = (2*X.T@X@beta_hat - 2*X.T@y)/ N\nbeta_hat2 = beta_hat - 0.1*slope\nyhat2 = X@beta_hat2\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.reshape(-1),'-')\nplt.plot(x,yhat2.reshape(-1),'-')\n\n\n\n\n\n\n\n\n초록색이 좀 더 나아보인다.\n\n#beta_hats # (2,1) (2,1) -&gt; (2,2) (2,1) -&gt; (2.3) (2,1)\n\n\nbeta_hat = np.array([-3,-2]).reshape(2,1)\nbeta_hats = beta_hat # beta_hats = beta_hat.copy() 가 더 안전한 코드입니다.\nfor i in range(1,30):\n    yhat = X@beta_hat\n    slope = (2*X.T@X@beta_hat - 2*X.T@y) / N\n    beta_hat = beta_hat - 0.1*slope # 0.1은 적당, 0.3은 쪼금빠르지만 그래도 적당, 0.9는 너무 나간것같음, 1.0 은 수렴안함, 1.2   #학습률에 따라 달라짐\n    beta_hats = np.concatenate([beta_hats,beta_hat],axis=1)\n\n\nbeta_hats    #1.0으로 돌려서 2.5, 3.9 안 나옴\n\narray([[-3.        ,  7.12238255, -1.2575366 ,  5.73166742, -0.1555309 ,\n         4.86767499,  0.51106397,  4.36611576,  0.87316777,  4.12348617,\n         1.01165173,  4.07771926,  0.97282343,  4.19586617,  0.77814101,\n         4.46653491,  0.4299822 ,  4.89562729, -0.08537358,  5.50446319,\n        -0.79684366,  6.32975688, -1.74933031,  7.42517729, -3.00603683,\n         8.86442507, -4.6523303 , 10.74592463, -6.80132547, 13.19938129],\n       [-2.        ,  8.70824998,  0.16165717,  6.93399596,  1.62435964,\n         5.72089586,  2.63858056,  4.86387722,  3.37280529,  4.22385379,\n         3.94259478,  3.70397678,  4.43004465,  3.23363047,  4.89701606,\n         2.75741782,  5.39439054,  2.22728903,  5.96886945,  1.59655409,\n         6.66836857,  0.81489407,  7.54676324, -0.17628423,  8.66856437,\n        -1.44867655, 10.11401544, -3.09256176, 11.98507323, -5.22340389]])\n\n\n\nb0hats = beta_hats[0].tolist()\nb1hats = beta_hats[1].tolist()\n\n\nb0hats\n\n[-3.0,\n 7.122382546470083,\n -1.2575365964121268,\n 5.7316674228791715,\n -0.15553089818020815,\n 4.867674988051825,\n 0.5110639664542092,\n 4.366115757831659,\n 0.8731677653649692,\n 4.123486170810972,\n 1.0116517257636013,\n 4.077719259741098,\n 0.9728234257107906,\n 4.195866174874318,\n 0.7781410146840524,\n 4.466534913549843,\n 0.42998219839798413,\n 4.895627292682776,\n -0.08537357736748952,\n 5.504463186820763,\n -0.7968436603883129,\n 6.329756875811346,\n -1.7493303057929674,\n 7.4251772934225615,\n -3.006036826668189,\n 8.864425071904613,\n -4.652330299695423,\n 10.745924632959083,\n -6.801325467758689,\n 13.199381289458147]\n\n\n\nnp.linalg.inv(X.T@X) @ X.T @ y\n\narray([[2.5451404 ],\n       [3.94818596]])\n\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n&lt;Figure size 1200x500 with 0 Axes&gt;\n\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림\nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*x)\n# ax2: 오른쪽그림 - loss function 그릴거\nβ0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\nβ0=β0.reshape(-1)\nβ1=β1.reshape(-1)\nloss_fn = lambda b0,b1: np.sum((y-b0-b1*x)**2)\nloss = list(map(loss_fn, β0,β1))\nax2.scatter(β0,β1,loss,alpha=0.02)\nax2.scatter(2.5451404,3.94818596,loss_fn(2.5451404,3.94818596),s=200,marker='*')\n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*x)\n    ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\")\n\nani = animation.FuncAnimation(fig,animate,frames=30)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n예제2\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i}\\)\n\nnp.random.seed(43052)\nN= 100\nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5\ny= 2.5+4*np.exp(-x) +epsilon\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\nX= np.stack([np.ones(N),np.exp(-x)],axis=1)\ny= y.reshape(N,1)\n\n\nbeta_hat = np.array([-3,-2]).reshape(2,1)\nbeta_hats = beta_hat.copy() # shallow copy, deep copy &lt;--- 여름 방학 특강\nfor i in range(1,30):\n    yhat = X@beta_hat\n    slope = (2*X.T@X@beta_hat - 2*X.T@y) /N\n    beta_hat = beta_hat - 0.05*slope\n    beta_hats = np.concatenate([beta_hats,beta_hat],axis=1)\n\n\nbeta_hats\n\narray([[-3.        , -1.74671631, -0.82428979, -0.14453919,  0.35720029,\n         0.72834869,  1.0036803 ,  1.20869624,  1.36209751,  1.47759851,\n         1.56525696,  1.63244908,  1.68458472,  1.72563174,  1.75850062,\n         1.78532638,  1.80767543,  1.82669717,  1.84323521,  1.85790889,\n         1.8711731 ,  1.88336212,  1.89472176,  1.90543297,  1.91562909,\n         1.92540859,  1.93484428,  1.94399023,  1.9528867 ,  1.96156382],\n       [-2.        , -0.25663415,  1.01939241,  1.95275596,  2.63488171,\n         3.13281171,  3.49570765,  3.75961951,  3.95098231,  4.08918044,\n         4.18842797,  4.2591476 ,  4.30898175,  4.34353413,  4.36691339,\n         4.38213187,  4.39139801,  4.39633075,  4.39811673,  4.3976256 ,\n         4.3954946 ,  4.3921905 ,  4.38805511,  4.3833386 ,  4.37822393,\n         4.37284482,  4.36729887,  4.36165718,  4.35597148,  4.35027923]])\n\n\n\nb0hats= beta_hats[0].tolist()\nb1hats= beta_hats[1].tolist()\n\n\nnp.linalg.inv(X.T@X)@X.T@y\n\narray([[2.46307644],\n       [3.99681332]])\n\n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n&lt;Figure size 1200x500 with 0 Axes&gt;\n\n\n\n#list(map(lambda b0,b1 : np.sum((y-b0-b1*x)**2), β0,β1))\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림\nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*np.exp(-x))\n# ax2: 오른쪽그림\nβ0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\nβ0=β0.reshape(-1)\nβ1=β1.reshape(-1)\nloss_fn = lambda b0,b1: np.sum((y-b0-b1*np.exp(-x))**2)\nloss = list(map(loss_fn, β0,β1))\nax2.scatter(β0,β1,loss,alpha=0.02)\nax2.scatter(2.46307644,3.99681332,loss_fn(2.46307644,3.99681332),s=200,marker='*')\n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*np.exp(-x))\n    ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\")\n\nani = animation.FuncAnimation(fig,animate,frames=30)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n예제3\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i} + \\beta_2 \\cos(5x_i)\\)\n\nnp.random.seed(43052)\nN= 100\nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5\ny= 2.5+4*np.exp(-x) + 5*np.cos(5*x) + epsilon\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\nX=np.stack([np.ones(N),np.exp(-x),np.cos(5*x)],axis=1)\ny=y.reshape(N,1)\n\n\nbeta_hat = np.array([-3,-2,-1]).reshape(3,1)\nbeta_hats = beta_hat.copy()\nfor i in range(1,30):\n    yhat = X@beta_hat\n    slope = (2*X.T@X@beta_hat -2*X.T@y) /N\n    beta_hat = beta_hat - 0.1 * slope\n    beta_hats= np.concatenate([beta_hats,beta_hat],axis=1)\n\n\nbeta_hats\n\narray([[-3.        , -0.71767532,  0.36255782,  0.89072137,  1.16423101,\n         1.31925078,  1.41819551,  1.48974454,  1.54713983,  1.59655416,\n         1.64091846,  1.68167278,  1.71956758,  1.75503084,  1.78833646,\n         1.81968188,  1.84922398,  1.877096  ,  1.90341567,  1.92828934,\n         1.95181415,  1.97407943,  1.99516755,  2.01515463,  2.0341111 ,\n         2.05210214,  2.06918818,  2.08542523,  2.10086524,  2.11555643],\n       [-2.        ,  1.16947474,  2.64116513,  3.33411605,  3.66880042,\n         3.83768856,  3.92897389,  3.98315095,  4.01888831,  4.04486085,\n         4.06516144,  4.08177665,  4.09571971,  4.10754954,  4.1176088 ,\n         4.12613352,  4.13330391,  4.13926816,  4.14415391,  4.14807403,\n         4.15112966,  4.1534121 ,  4.15500404,  4.15598045,  4.15640936,\n         4.15635249,  4.15586584,  4.15500014,  4.15380139,  4.1523112 ],\n       [-1.        , -0.95492718, -0.66119313, -0.27681968,  0.12788212,\n         0.52254445,  0.89491388,  1.24088224,  1.55993978,  1.85310654,\n         2.12199631,  2.36839745,  2.59408948,  2.8007666 ,  2.99000967,\n         3.16327964,  3.32192026,  3.46716468,  3.60014318,  3.72189116,\n         3.83335689,  3.93540864,  4.02884144,  4.11438316,  4.19270026,\n         4.26440288,  4.33004965,  4.39015202,  4.44517824,  4.49555703]])\n\n\n\nb0hats,b1hats,b2hats = beta_hats\n\n\nnp.linalg.inv(X.T@X) @ X.T @ y\n\narray([[2.46597526],\n       [4.00095138],\n       [5.04161877]])\n\n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n&lt;Figure size 1200x500 with 0 Axes&gt;\n\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림\nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*np.exp(-x) + b2hats[0]*np.cos(5*x))\n# ax2: 오른쪽그림\n# β0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\n# β0=β0.reshape(-1)\n# β1=β1.reshape(-1)\n# loss_fn = lambda b0,b1: np.sum((y-b0-b1*np.exp(-x))**2)\n# loss = list(map(loss_fn, β0,β1))\n# ax2.scatter(β0,β1,loss,alpha=0.02)\n# ax2.scatter(2.46307644,3.99681332,loss_fn(2.46307644,3.99681332),s=200,marker='*')\n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*np.exp(-x) + b2hats[i]*np.cos(5*x))\n    # ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\")\n\nani = animation.FuncAnimation(fig,animate,frames=30)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n예제3: 케라스로 해보자!\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i} + \\beta_2 \\cos(5x_i)\\)\n\nnp.random.seed(43052)\nN= 100\nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5\ny= 2.5+4*np.exp(-x) + 5*np.cos(5*x) + epsilon\n\n\nX=np.stack([np.ones(N),np.exp(-x),np.cos(5*x)],axis=1)\ny=y.reshape(N,1)\n\n\nnet = tf.keras.Sequential() # 1: 네트워크 생성\nnet.add(tf.keras.layers.Dense(1,use_bias=False)) # 2: add layer\nnet.compile(tf.optimizers.SGD(0.1), loss='mse') # 3: compile\nnet.fit(X,y,epochs=30, batch_size=N) # 4: fit\n\nEpoch 1/30\n1/1 [==============================] - 0s 191ms/step - loss: 54.6305\nEpoch 2/30\n1/1 [==============================] - 0s 5ms/step - loss: 20.0028\nEpoch 3/30\n1/1 [==============================] - 0s 6ms/step - loss: 11.4068\nEpoch 4/30\n1/1 [==============================] - 0s 6ms/step - loss: 8.4731\nEpoch 5/30\n1/1 [==============================] - 0s 5ms/step - loss: 6.9071\nEpoch 6/30\n1/1 [==============================] - 0s 8ms/step - loss: 5.7812\nEpoch 7/30\n1/1 [==============================] - 0s 6ms/step - loss: 4.8763\nEpoch 8/30\n1/1 [==============================] - 0s 4ms/step - loss: 4.1259\nEpoch 9/30\n1/1 [==============================] - 0s 8ms/step - loss: 3.4984\nEpoch 10/30\n1/1 [==============================] - 0s 5ms/step - loss: 2.9728\nEpoch 11/30\n1/1 [==============================] - 0s 6ms/step - loss: 2.5322\nEpoch 12/30\n1/1 [==============================] - 0s 7ms/step - loss: 2.1628\nEpoch 13/30\n1/1 [==============================] - 0s 5ms/step - loss: 1.8530\nEpoch 14/30\n1/1 [==============================] - 0s 5ms/step - loss: 1.5934\nEpoch 15/30\n1/1 [==============================] - 0s 16ms/step - loss: 1.3756\nEpoch 16/30\n1/1 [==============================] - 0s 11ms/step - loss: 1.1930\nEpoch 17/30\n1/1 [==============================] - 0s 6ms/step - loss: 1.0399\nEpoch 18/30\n1/1 [==============================] - 0s 4ms/step - loss: 0.9116\nEpoch 19/30\n1/1 [==============================] - 0s 4ms/step - loss: 0.8039\nEpoch 20/30\n1/1 [==============================] - 0s 4ms/step - loss: 0.7136\nEpoch 21/30\n1/1 [==============================] - 0s 5ms/step - loss: 0.6379\nEpoch 22/30\n1/1 [==============================] - 0s 10ms/step - loss: 0.5743\nEpoch 23/30\n1/1 [==============================] - 0s 5ms/step - loss: 0.5211\nEpoch 24/30\n1/1 [==============================] - 0s 6ms/step - loss: 0.4764\nEpoch 25/30\n1/1 [==============================] - 0s 5ms/step - loss: 0.4389\nEpoch 26/30\n1/1 [==============================] - 0s 4ms/step - loss: 0.4074\nEpoch 27/30\n1/1 [==============================] - 0s 7ms/step - loss: 0.3810\nEpoch 28/30\n1/1 [==============================] - 0s 4ms/step - loss: 0.3588\nEpoch 29/30\n1/1 [==============================] - 0s 4ms/step - loss: 0.3402\nEpoch 30/30\n1/1 [==============================] - 0s 4ms/step - loss: 0.3246\n\n\n&lt;keras.src.callbacks.History at 0x7ef5af805a20&gt;\n\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense_9/kernel:0' shape=(3, 1) dtype=float32, numpy=\n array([[2.5445633],\n        [3.8758123],\n        [4.6478696]], dtype=float32)&gt;]\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@net.weights).reshape(-1),'--')\n\n\n\n\n\n\n\n\n\n\n\n숙제\n\n예제2: 케라스를 이용하여 아래를 만족하는 적절한 \\(\\beta_0\\)와 \\(\\beta_1\\)을 구하라. 적합결과를 시각화하라. (애니메이션 시각화 X)\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i}\\)\n\nnp.random.seed(43052)\nN= 100\nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5\ny= 2.5+4*np.exp(-x) +epsilon",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "05. net 설계 (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-09-19-03. 경사하강법 (1).html",
    "href": "posts/study/2023-09-19-03. 경사하강법 (1).html",
    "title": "03. 경사하강법 (1)",
    "section": "",
    "text": "라이브러리\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow.experimental.numpy as tnp\n\n\ntnp.experimental_enable_numpy_behavior()\n\n\n\nGrid Search의 문제\n\n최적을 값을 찾기위해 임의로 범위를 지정했을 때 그 범위 안에 optimal한 값이 존재 하지 않을 수 있음. -&gt; 넓은 범위를 탐색하고 싶음.\n비효율적임. 모든 값을 일일이 다 찾아야하고, 최적의 값을 찾았음에도 불구하고 탐색 계속 진행..\n\n\n\n경사하강법을 이용한 최솟값 찾기\n\n임의의 값을 세팅하고 그 값을 기준으로 조금씩 값을 증가 혹은 갑소시킨 후 loss 가 더 적은 쪽으로 움직이면서 최적의 값 찾기\n\n\\[y=(x-1)^2\\]\n정답: \\(x=1\\)임 (접선의 기울기 0이 되는 값)\n\nx= -3 으로 세팅\n\n\n(-3-1)**2\n\n16\n\n\n\nprint((-2.99-1)**2)\nprint((-3.01-1)**2)\n\n15.920100000000001\n16.080099999999998\n\n\n-&gt; 오른쪽으로 이동하는 것이 유리\n\n# x 세팅\nx = tf.Variable(-3.0)\n\n# x = -3일 때 loss값 계산\nwith tf.GradientTape(persistent=True) as tape:\n    loss = (x-1)**2\n    \n# x에 대하여 미분    \ntape.gradient(loss, x)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=-8.0&gt;\n\n\n\n시도1\n0.01만큼 오른쪽 이동\n\n\nalpha = 0.01 / 8\nx = tf.Variable(-3.0)\n\nfor k in range(100):\n    with tf.GradientTape(persistent=True) as tape:\n        loss = (x-1)**2\n    x.assign_sub(alpha * tape.gradient(loss, x))\n\n\nx\n\n&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-2.1142282&gt;\n\n\n\n시도2\n0.1만큼 오른쪽 이동\n\n\nalpha = 0.1 / 8\nx = tf.Variable(-3.0)\n\nfor k in range(100):\n    with tf.GradientTape(persistent=True) as tape:\n        loss = (x-1)**2\n    x.assign_sub(alpha * tape.gradient(loss, x))\n    \nx\n\n&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.68193084&gt;\n\n\n\n시도3\n0.05 만큼 오른쪽 이동\n\n\nalpha = 0.05 / 8\nx = tf.Variable(-3.0)\n\nfor k in range(100):\n    with tf.GradientTape(persistent=True) as tape:\n        loss = (x-1)**2\n    x.assign_sub(alpha * tape.gradient(loss, x))\n    \nx\n\n&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.13702613&gt;\n\n\n\n\n시각화\n\n# x_list = list(range(-3,2))\n# loss_list= [(k-1)**2 for k in x_list]\n\n\n# x 및 alpha 정의 \nx = tf.Variable(-3.0)\nalpha = 0.05 / 8\n\n# 빈 리스트 생성\nx_list = []\nloss_list=[]\n\n# 초기 값으로 리스트 채우기\nx_list.append(x.numpy())\nloss_list.append((x.numpy()-1)**2)\n\n\nx_list, loss_list\n\n([-3.0], [16.0])\n\n\n\nx = tf.Variable(-3.0)\nalpha = 0.05 / 8\n\n# x 값 0.05씩 이동 100번 반복\nfor k in range (100):\n    with tf.GradientTape(persistent=True) as tape:\n        loss = (x-1)**2\n    x.assign_sub(tape.gradient(loss, x)*alpha)\n    x_list.append(x.numpy())\n    loss_list.append((x.numpy()-1)**2)\n\n\n# 시각화 라이브러리 import\nplt.rcParams[\"animation.html\"]=\"jshtml\"\nfrom matplotlib import animation\n\n\n_x = np.linspace(-6,8,100)\n\n\nfig = plt.figure()\nax = fig.add_subplot()\nax.plot(_x,(_x-1)**2)\npnts, = ax.plot(x_list[0],loss_list[0],'or')\n\n\n\n\n\n\n\n\n\ndef animate(i):\n    pnts.set_xdata(x_list[:(i+1)])\n    pnts.set_ydata(loss_list[:(i+1)])\n\n\nani = animation.FuncAnimation(fig,animate,frames=100)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "03. 경사하강법 (1)"
    ]
  },
  {
    "objectID": "posts/study/2023-09-12-01. tensorflow (1).html",
    "href": "posts/study/2023-09-12-01. tensorflow (1).html",
    "title": "01. tensorflow (1)",
    "section": "",
    "text": "강의노트\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-z8oR8bQZHR0mpy_9OcsWOz\n\n\n\nTensorFlow 란?\n\n-&gt; 딥러닝 및 기계 학습을 위한 오픈소스 딥러닝 프레임워크 중 하나\n\nCNN, RNN 등 다양한 딥러닝 모델 구현 도구 포함\n텐서보드 지원(시각화)\n분산 컴퓨팅 지원 및 확장성 : GPU 등 하드웨어 가속 지원\n자동 미분 기능 : 그래디언드(기울기)를 자동으로 계산하여 역전파 알고리즘을 구현 지원 등\n\n\n\nTensor\n-&gt; 다차원 배열로, 수치데이터를 저장하고 다루는데 사용함. 보통 백터, 행렬, n차원 배열 등의 형태를 가지며, 데이터의 종류에 따라 다양한 유형이 존재함 1. 머신러닝 및 딥러닝 데이터가 주로 텐서로 표현되고(이미지, 텍스트, 오디오 등), 2. 신경망의 학습 및 추론 과정에서 가중치와 편향을 조정하고 데이터를 변화하는데 텐서 연산을 기반으로 구성\n\n\n\n\nTensorFlow 설치하기(참고) : https://brunch.co.kr/@mapthecity/15\n\n\n\n\nimport\n\nimport tensorflow as tf\nimport numpy as np\n\n\ntf.config.experimental.list_physical_devices('GPU')\n\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n\n\n\n# physical_device:GPU:0 =&gt; TensorFlow가 인식한 GPU들 중에서 첫번째 GPU를 사용한다는 뜻\n\n\ntf.__version__\n\n'2.10.0'\n\n\n\n\ntf.constant()\n\n파이썬의 list나 numpy 배열과 같은 데이터를 받아 Tensor로 변환하는 함수\n\n\n예비학습: 중첩리스트\n- 리스트\n\nlst = [1,2,4,5,6]\nlst \n\n[1, 2, 4, 5, 6]\n\n\n\nlst[1] # 두번쨰원소 \n\n2\n\n\n\nlst[-1] # 마지막원소 \n\n6\n\n\n- (2,2) matrix 느낌의 list\n\nlst= [[1,2],[3,4]]\nlst\n\n[[1, 2], [3, 4]]\n\n\n위를 아래와 같은 매트릭스로 생각할수 있다.\n1 2 \n3 4 \n\nprint(lst[0][0]) # (1,1) \nprint(lst[0][1]) # (1,2) \nprint(lst[1][0]) # (2,1) \nprint(lst[1][1]) # (2,2) \n\n1\n2\n3\n4\n\n\n- (4,1) matrix 느낌의 list\n\nlst=[[1],[2],[3],[4]] # (4,1) matrix = 길이가 4인 col-vector\nlst\n\n[[1], [2], [3], [4]]\n\n\n- (1,4) matrix 느낌의 list\n\nlst=[[1,2,3,4]] # (1,4) matrix = 길이가 4인 row-vector \nlst\n\n[[1, 2, 3, 4]]\n\n\n\n\n선언\n- 스칼라(0차원)\n\ntf.constant(3.14)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=3.14&gt;\n\n\n\ntf.constant(3.14)+tf.constant(3.14)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=6.28&gt;\n\n\n- 벡터(1차원)\n\n_vector=tf.constant([1,2,3])\n\n\n_vector[-1]\n\n&lt;tf.Tensor: shape=(), dtype=int32, numpy=3&gt;\n\n\n- 매트릭스 즉, 행렬(2차원)\n\n_matrix= tf.constant([[1,0],[0,1]])\n_matrix\n\n&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 0],\n       [0, 1]], dtype=int32)&gt;\n\n\n- array\n\ntf.constant([[[0,1,1],[1,2,-1]],[[0,1,2],[1,2,-1]]])\n\n&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 0,  1,  1],\n        [ 1,  2, -1]],\n\n       [[ 0,  1,  2],\n        [ 1,  2, -1]]], dtype=int32)&gt;\n\n\n\n\n인덱싱 : 파이썬 동일\n\ntype(tf.constant(3.14))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n_matrix = tf.constant([[1,2],[3,4]])\n_matrix\n\n&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)&gt;\n\n\n\n_matrix[0][0]\n\n&lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;\n\n\n\n_matrix[0]\n\n&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)&gt;\n\n\n\n_matrix[0,:] # 행, 열 순서\n\n&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)&gt;\n\n\n\n_matrix[:,0]\n\n&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 3], dtype=int32)&gt;\n\n\n\n\ntf.constant는 불편하다.\n- 불편한점 1. 모든 원소가 같은 dtype을 가지고 있어야함. 2. 원소 수정이 불가능함. 3. 묵시적 형변환이 불가능하다.\n- 원소수정이 불가능함\n\na=tf.constant([1,22,33])\na\n\n&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1, 22, 33], dtype=int32)&gt;\n\n\n\na[0]=11\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n- 묵시적 형변환이 불가능하다\n\ntf.constant(1)+tf.constant(3.14)\n\nInvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]\n\n\n\ntf.constant(1.0)+tf.constant(3.14)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=4.1400003&gt;\n\n\n\n# cast 이용(Tensor의 형변환) : tf.constant(1.0)+tf.constant(3.14)\na1 = tf.constant(1.0)\nb1 = tf.constant(3.14)\nd1 = tf.cast(b1, tf.float32)\nprint(d1)\nprint(tf.add(a1,d1))\n\ntf.Tensor(3.14, shape=(), dtype=float32)\ntf.Tensor(4.1400003, shape=(), dtype=float32)\n\n\n- 같은 float도 안되는 경우가 있음\n\ntf.constant(1.0,dtype=tf.float64)\n\n&lt;tf.Tensor: shape=(), dtype=float64, numpy=1.0&gt;\n\n\n\ntf.constant(3.14)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=3.14&gt;\n\n\n\ntf.constant(1.0,dtype=tf.float64)+tf.constant(3.14)\n\nInvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:AddV2]\n\n\n\n\ntf.constant \\(\\to\\) 넘파이\n\nnp.array(tf.constant(1)) # 방법1\n\narray(1, dtype=int32)\n\n\n\na=tf.constant([3.14,-3.14])\ntype(a)\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\na.numpy()\n\narray([ 3.14, -3.14], dtype=float32)\n\n\n\n\n연산\n- 더하기\n\na=tf.constant([1,2])\nb=tf.constant([3,4])\na+b\n\n&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)&gt;\n\n\n\ntf.add(a,b)\n\n&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)&gt;\n\n\n- 곱하기\n\na=tf.constant([[1,2],[3,4]])\nb=tf.constant([[5,6],[7,8]])\na*b\n\n&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[ 5, 12],\n       [21, 32]], dtype=int32)&gt;\n\n\n\ntf.multiply(a,b)\n\n&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[ 5, 12],\n       [21, 32]], dtype=int32)&gt;\n\n\n- 매트릭스의 곱(2차원에서만 작동)\n\na=tf.constant([[1,0],[0,1]]) # (2,2)\nb=tf.constant([[5],[7]]) # (2,1) \na@b\n\n&lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[5],\n       [7]], dtype=int32)&gt;\n\n\n\ntf.matmul(a,b)\n\n&lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[5],\n       [7]], dtype=int32)&gt;\n\n\n- 역행렬\n\n\n\n\na=tf.constant([[1,0],[0,2]])\na\n\n&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 0],\n       [0, 2]], dtype=int32)&gt;\n\n\n\ntf.linalg.inv(a)\n\nInvalidArgumentError: Value for attr 'T' of int32 is not in the list of allowed values: double, float, half, complex64, complex128\n    ; NodeDef: {{node MatrixInverse}}; Op&lt;name=MatrixInverse; signature=input:T -&gt; output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]&gt; [Op:MatrixInverse]\n\n\n\na=tf.constant([[1.0,0.0],[0.0,2.0]])\ntf.linalg.inv(a)\n\n&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[1. , 0. ],\n       [0. , 0.5]], dtype=float32)&gt;\n\n\n- tf.linalg. + tab을 누르면 좋아보이는 연산들 많음\n\na=tf.constant([[1.0,2.0],[3.0,4.0]])\nprint(a)\ntf.linalg.det(a)\n\ntf.Tensor(\n[[1. 2.]\n [3. 4.]], shape=(2, 2), dtype=float32)\n\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=-2.0&gt;\n\n\n\n?tf.linalg.det  # 행렬의 특성 설명\n\n\nSignature: tf.linalg.det(input, name=None)\nDocstring:\nComputes the determinant of one or more square matrices.\nThe input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\nform square matrices. The output is a tensor containing the determinants\nfor all input submatrices `[..., :, :]`.\nArgs:\n  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.\n    Shape is `[..., M, M]`.\n  name: A name for the operation (optional).\nReturns:\n  A `Tensor`. Has the same type as `input`.\nFile:      c:\\users\\user\\anaconda3\\envs\\dx_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_linalg_ops.py\nType:      function\n\n\n\n\n\ntf.linalg.trace(a)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;\n\n\n::: {#578e284a-00f1-4ee3-94a3-9dd86bf0e2b8 .cell jupyter=‘{“outputs_hidden”:true}’ tags=‘[]’ execution_count=15}\n?tf.linalg.trace # 대각선 상의 원소의 합\n::: {.cell-output .cell-output-display}\n\nSignature: tf.linalg.trace(x, name=None)\nDocstring:\nCompute the trace of a tensor `x`.\n`trace(x)` returns the sum along the main diagonal of each inner-most matrix\nin x. If x is of rank `k` with shape `[I, J, K, ..., L, M, N]`, then output\nis a tensor of rank `k-2` with dimensions `[I, J, K, ..., L]` where\n`output[i, j, k, ..., l] = trace(x[i, j, k, ..., l, :, :])`\nFor example:\n```python\nx = tf.constant([[1, 2], [3, 4]])\ntf.linalg.trace(x)  # 5\nx = tf.constant([[1, 2, 3],\n                 [4, 5, 6],\n                 [7, 8, 9]])\ntf.linalg.trace(x)  # 15\nx = tf.constant([[[1, 2, 3],\n                  [4, 5, 6],\n                  [7, 8, 9]],\n                 [[-1, -2, -3],\n                  [-4, -5, -6],\n                  [-7, -8, -9]]])\ntf.linalg.trace(x)  # [15, -15]\nArgs: x: tensor. name: A name for the operation (optional). Returns: The trace of input tensor. File: c:_env-packages_ops.py Type: function\n\n:::\n\n:::\n:::\n\n\n#### 형태변환\n\n`-` 기본: tf.reshape() 를 이용\n\n::: {#07db8721-4087-47a5-8b73-15f1c64eb65f .cell execution_count=44}\n``` {.python .cell-code}\na=tf.constant([1,2,3,4])\na\n\n&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;\n\n\n\ntf.reshape(a,(4,1))\n\n&lt;tf.Tensor: shape=(4, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]], dtype=int32)&gt;\n\n\n\ntf.reshape(a,(2,2))\n\n&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)&gt;\n\n\n\ntf.reshape(a,(2,2,1))\n\n&lt;tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\narray([[[1],\n        [2]],\n\n       [[3],\n        [4]]], dtype=int32)&gt;\n\n\n- 다차원\n\na=tf.constant([1,2,3,4,5,6,7,8,9,10,11,12])\na\n\n&lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)&gt;\n\n\n\ntf.reshape(a,(2,2,3))\n\n&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)&gt;\n\n\n\ntf.reshape(a,(4,3))\n\n&lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy=\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]], dtype=int32)&gt;\n\n\n\na=tf.constant([1,2,3,4,5,6,7,8,9,10,11,12])\na\n\n&lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)&gt;\n\n\n\ntf.reshape(a,(4,-1)) # -1 이면 전체 크기가 일정하게 유지되도록 해당 차원의 크기가 계산됨\n\n&lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy=\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]], dtype=int32)&gt;\n\n\n\ntf.reshape(a,(2,2,-1))\n\n&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)&gt;\n\n\n\nb=tf.reshape(a,(2,2,-1))\nb\n\n&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)&gt;\n\n\n\ntf.reshape(b,-1)\n\n&lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)&gt;\n\n\n\n\n선언고급\n- 다른 자료형 (리스트나 넘파이)로 만들고 바꾸는것도 좋다.\n\nnp.diag([1,2,3,4]) # np.diag : 대각 행렬 생성\n\narray([[1, 0, 0, 0],\n       [0, 2, 0, 0],\n       [0, 0, 3, 0],\n       [0, 0, 0, 4]])\n\n\n\ntf.constant(np.diag([1,2,3,4]))\n\n&lt;tf.Tensor: shape=(4, 4), dtype=int64, numpy=\narray([[1, 0, 0, 0],\n       [0, 2, 0, 0],\n       [0, 0, 3, 0],\n       [0, 0, 0, 4]])&gt;\n\n\n- tf.ones, tf.zeros\n\ntf.zeros([3,3])\n\n&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)&gt;\n\n\n\ntf.reshape(tf.constant([0]*9),(3,3))\n\n&lt;tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0]], dtype=int32)&gt;\n\n\n- range(10)\n\na=range(0,12)\ntf.constant(a)\n\n&lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int32)&gt;\n\n\n\ntf.constant(range(1,20,3)) \n\n&lt;tf.Tensor: shape=(7,), dtype=int32, numpy=array([ 1,  4,  7, 10, 13, 16, 19], dtype=int32)&gt;\n\n\n- tf.linspace\n\ntf.linspace(0,1,10)\n\n&lt;tf.Tensor: shape=(10,), dtype=float64, numpy=\narray([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])&gt;\n\n\n\n\ntf.concat\n- (2,1) concat (2,1) =&gt; (2,2) - 두번째 축이 바뀌었다. =&gt; axis=1\n\na=tf.constant([[1],[2]])\nb=tf.constant([[3],[4]])\na,b\n\n(&lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[1],\n        [2]], dtype=int32)&gt;,\n &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[3],\n        [4]], dtype=int32)&gt;)\n\n\n\ntf.concat([a,b],axis=1)\n\n&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 3],\n       [2, 4]], dtype=int32)&gt;\n\n\n- (2,1) concat (2,1) =&gt; (4,1) - 첫번째 축이 바뀌었다. =&gt; axis=0\n\na=tf.constant([[1],[2]])\nb=tf.constant([[3],[4]])\na,b\n\n(&lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[1],\n        [2]], dtype=int32)&gt;,\n &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[3],\n        [4]], dtype=int32)&gt;)\n\n\n\ntf.concat([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(4, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]], dtype=int32)&gt;\n\n\n- (1,2) concat (1,2) =&gt; (2,2) - 첫번째 // axis=0\n\na=tf.constant([[1,2]])\nb=tf.constant([[3,4]])\n\n\ntf.concat([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)&gt;\n\n\n- (1,2) concat (1,2) =&gt; (1,4) - 첫번째 // axis=0\n- (2,3,4,5) concat (2,3,4,5) =&gt; (4,3,4,5) - 첫번째 // axis=0\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(4, 3, 4, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119]]],\n\n\n       [[[   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)&gt;\n\n\n- (2,3,4,5) concat (2,3,4,5) =&gt; (2,6,4,5) - 두번째 // axis=1\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=1)\n\n&lt;tf.Tensor: shape=(2, 6, 4, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59]],\n\n        [[   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119]],\n\n        [[ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)&gt;\n\n\n- (2,3,4,5) concat (2,3,4,5) =&gt; (2,3,8,5) - 세번째 // axis=2\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=2)\n\n&lt;tf.Tensor: shape=(2, 3, 8, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19],\n         [   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39],\n         [ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59],\n         [ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79],\n         [ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99],\n         [ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119],\n         [-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)&gt;\n\n\n- (2,3,4,5) concat (2,3,4,5) =&gt; (2,3,4,10) - 네번째 // axis=3 # 0,1,2,3 // -4 -3 -2 -1\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=-1)\n\n&lt;tf.Tensor: shape=(2, 3, 4, 10), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4,    0,   -1,   -2,   -3,   -4],\n         [   5,    6,    7,    8,    9,   -5,   -6,   -7,   -8,   -9],\n         [  10,   11,   12,   13,   14,  -10,  -11,  -12,  -13,  -14],\n         [  15,   16,   17,   18,   19,  -15,  -16,  -17,  -18,  -19]],\n\n        [[  20,   21,   22,   23,   24,  -20,  -21,  -22,  -23,  -24],\n         [  25,   26,   27,   28,   29,  -25,  -26,  -27,  -28,  -29],\n         [  30,   31,   32,   33,   34,  -30,  -31,  -32,  -33,  -34],\n         [  35,   36,   37,   38,   39,  -35,  -36,  -37,  -38,  -39]],\n\n        [[  40,   41,   42,   43,   44,  -40,  -41,  -42,  -43,  -44],\n         [  45,   46,   47,   48,   49,  -45,  -46,  -47,  -48,  -49],\n         [  50,   51,   52,   53,   54,  -50,  -51,  -52,  -53,  -54],\n         [  55,   56,   57,   58,   59,  -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64,  -60,  -61,  -62,  -63,  -64],\n         [  65,   66,   67,   68,   69,  -65,  -66,  -67,  -68,  -69],\n         [  70,   71,   72,   73,   74,  -70,  -71,  -72,  -73,  -74],\n         [  75,   76,   77,   78,   79,  -75,  -76,  -77,  -78,  -79]],\n\n        [[  80,   81,   82,   83,   84,  -80,  -81,  -82,  -83,  -84],\n         [  85,   86,   87,   88,   89,  -85,  -86,  -87,  -88,  -89],\n         [  90,   91,   92,   93,   94,  -90,  -91,  -92,  -93,  -94],\n         [  95,   96,   97,   98,   99,  -95,  -96,  -97,  -98,  -99]],\n\n        [[ 100,  101,  102,  103,  104, -100, -101, -102, -103, -104],\n         [ 105,  106,  107,  108,  109, -105, -106, -107, -108, -109],\n         [ 110,  111,  112,  113,  114, -110, -111, -112, -113, -114],\n         [ 115,  116,  117,  118,  119, -115, -116, -117, -118, -119]]]],\n      dtype=int32)&gt;\n\n\n- (4,) concat (4,) =&gt; (8,) - 첫번째축? // axis=0\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;,\n &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)&gt;)\n\n\n\ntf.concat([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(8,), dtype=int32, numpy=array([ 1,  2,  3,  4, -1, -2, -3, -4], dtype=int32)&gt;\n\n\n- (4,) concat (4,) =&gt; (4,2) - 두번째축? // axis=1 ==&gt; 이런거없다..\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;,\n &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)&gt;)\n\n\n\ntf.concat([a,b],axis=1)\n\nInvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [-1, 1), but got 1 [Op:ConcatV2] name: concat\n\n\n\n\ntf.stack\n\n-&gt; Stacks a list of rank-R tensors into one rank-(R+1) tensor\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;,\n &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)&gt;)\n\n\n\ntf.stack([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy=\narray([[ 1,  2,  3,  4],\n       [-1, -2, -3, -4]], dtype=int32)&gt;\n\n\n\ntf.stack([a,b],axis=1)\n\n&lt;tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3],\n       [ 4, -4]], dtype=int32)&gt;\n\n\n\n\n\n\ntnp\n- tf는 넘파이에 비하여 텐서만들기가 너무힘듬\n\nnp.diag([1,2,3]).reshape(-1)\n\narray([1, 0, 0, 0, 2, 0, 0, 0, 3])\n\n\n\n넘파이는 이런식으로 np.diag()도 쓸수 있고 reshape을 메소드로 쓸 수도 있는데…\n\n\ntnp 사용방법 (불만해결방법)\n\nimport tensorflow.experimental.numpy as tnp\ntnp.experimental_enable_numpy_behavior()\n\n\ntype(tnp.array([1,2,3]))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n- int와 float을 더할 수 있음\n\ntnp.array([1,2,3])+tnp.array([1.0,2.0,3.0])\n\n&lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 6.])&gt;\n\n\n\ntf.constant([1,2,3])+tf.constant([1.0,2.0,3.0])\n\n&lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 6.])&gt;\n\n\n\ntnp.array(1)+tnp.array([1.0,2.0,3.0])\n\n&lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 3., 4.])&gt;\n\n\n\ntnp.diag([1,2,3])\n\n&lt;tf.Tensor: shape=(3, 3), dtype=int64, numpy=\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])&gt;\n\n\n\na=tnp.diag([1,2,3])\ntype(a)\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\na=tf.constant([1,2,3])\na.reshape(3,1)\n\n&lt;tf.Tensor: shape=(3, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3]], dtype=int32)&gt;\n\n\n\n\n선언고급\n\nnp.random.randn(5)\n\narray([0.67533519, 0.18494521, 0.76946432, 0.94461951, 1.15058192])\n\n\n\ntnp.random.randn(5) # 넘파이가 되면 나도 된다.\n\n&lt;tf.Tensor: shape=(5,), dtype=float64, numpy=array([-0.37112581, -0.31535817, -0.92963552, -0.68741888, -0.54859424])&gt;\n\n\n\n\n타입\n\ntype(tnp.random.randn(5))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n\ntf.contant로 만들어도 마치 넘파이인듯 쓰는 기능들\n- 묵시적형변환이 가능???\n\ntf.constant([1,1])+tf.constant([2.2,3.3]) # 브로드캐스팅 기능 : 모양이 다른 텐서들 간에 산술연산을 수행할 떄 TensorFlow가 텐서의 모양을 자동으로 맞춰줌\n\n&lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([3.20000005, 4.29999995])&gt;\n\n\n- 메소드를 쓸수 있음.\n\na= tnp.array([[1,2,3,4]])\na.T\n\n&lt;tf.Tensor: shape=(4, 1), dtype=int64, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]])&gt;\n\n\n\n\n그렇지만 np.array는 아님\n- 원소를 할당하는것은 불가능\n\na=tf.constant([1,2,3])\na\n\n&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)&gt;\n\n\n\na[0]=11\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\n\n\n그 밖의 : TensorFlow 활용 가이드\nhttps://www.tensorflow.org/api_docs/python/tf/Tensor",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "01. tensorflow (1)"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html",
    "href": "posts/2023-09-09-01. classification.html",
    "title": "01. Classification",
    "section": "",
    "text": "- 해당 책에서는 우리가 평소에 회귀분석에서 쓰던 \\(\\text {MSE}= \\frac {SSE}{n-(p+1)}\\) 이라고 표현하지 않는다.\n- 교재에서 말하는 \\(\\text{MSE}\\)란 다음과 같다.\n\\[\\text{MSE} = E[(\\hat y - y)^2]\\]\n- 즉, 예측값과 실제값의 차이를 제곱합으로 계산 후 평균을 내는것이다.\n- 이를 다시 나누어 보자\n\\[\\begin {align} E[(\\hat y - y)^2] &= Var(\\hat y) + \\text {bias}^2   \\\\\n                                                                &= E[(\\hat y - E(\\hat y ))^2] + E[(E(\\hat y) - y)^2] + Var(\\varepsilon) \\end {align}\\]\n- \\(Var(\\hat y) \\, \\to \\,\\) 훈련자료의 변화에 \\(\\hat y\\)가 얼마나 민감하게 반응하는가?\n- \\(\\text {bias}^2\\) : 실제자료를 모형으로 얼마나 가깝게 근사할 수 있는가? (만약, \\(E(\\hat y) = y\\) 일 경우 해당 추정량은 불편추정량이다.)\n\n\\(Var(\\hat y),\\,\\text {bias}^2\\) 는 reducible error로 어떤 모델을 선택하느냐에 따라 줄일 수 있는 오차이다.\n\n- \\(Var(\\varepsilon)\\) : 어떤 모델을 사용하건 줄일 수 없는 오차\n- Flexibility : 모델 복잡도 측도\n\nFlexibility가 높아지면 \\(Var(\\hat y)\\) 는 높아지고, \\(\\text {bias}\\)는 낮아진다. (trade-off)\n이를 바꿔말하면 더 유연한(복잡한) 모형은 더 큰 분산을 가지고 더 단순한 모형일수록 큰 편의를 가진다.\n훈련 데이터로 모델 적합시, bias를 낮추기 위해 Var를 높여 모델 복잡도를 지나치게 높이는 것은 좋은 선택이 아니다.\n아래의 예시는 모형의 복잡도가 너무 높으면 평가 데이터에 대한 MSE가 오히려 과대추정되는 “과적합 문제” 를 보여주고 있다.\n\n\n\n\n\n\n\n\n\n- 실제로 위의 원데이터는 일반적인 선형모형으로 적합해도 괜찮을 것 같다.\n- 왼쪽그림에서 지나치게 복잡하게 적합된 초록색 선을 살펴보자.\n\n훈련 MSE(회색선) 는 3개의 모델 중 가장 낮으나, 과적합 이슈로 평가 MSE(빨간색선) 가 과대추정된 것을 볼 수 있다.\n\n\n\n\n\n\n\n- 위 데이터는 ex1과 달리 일반적인 선형회귀모형으로 적합하면 안될것 같은 느낌이 든다.\n- 파란색선은 중간 정도로 적합된 복잡한 모형이고, 초록색선은 지나치게 적합된 모형이다.\n\n오른쪽 그림을 살펴보면 파란색선으로 적합된 모형의 Test MSE가 가장 낮음을 볼 수 있다.",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#ex1",
    "href": "posts/2023-09-09-01. classification.html#ex1",
    "title": "01. Classification",
    "section": "",
    "text": "- 실제로 위의 원데이터는 일반적인 선형모형으로 적합해도 괜찮을 것 같다.\n- 왼쪽그림에서 지나치게 복잡하게 적합된 초록색 선을 살펴보자.\n\n훈련 MSE(회색선) 는 3개의 모델 중 가장 낮으나, 과적합 이슈로 평가 MSE(빨간색선) 가 과대추정된 것을 볼 수 있다.",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#ex2",
    "href": "posts/2023-09-09-01. classification.html#ex2",
    "title": "01. Classification",
    "section": "",
    "text": "- 위 데이터는 ex1과 달리 일반적인 선형회귀모형으로 적합하면 안될것 같은 느낌이 든다.\n- 파란색선은 중간 정도로 적합된 복잡한 모형이고, 초록색선은 지나치게 적합된 모형이다.\n\n오른쪽 그림을 살펴보면 파란색선으로 적합된 모형의 Test MSE가 가장 낮음을 볼 수 있다.",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#summary",
    "href": "posts/2023-09-09-01. classification.html#summary",
    "title": "01. Classification",
    "section": "summary",
    "text": "summary\n1 정확도 : 전체에서 예측값과 실제값이 일치하는 비율\n2 정밀도 : 내가 참이라고 예측한 것 중에 실제로 참인 비율 (전, 이걸 모델의 건방짐이라고 외웠습니다.)\n3 재현율 : 실제 참인 것들 중에서 모델이 참이라고 예측한 비율 (회사의 입장)",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#로지스틱-회귀모형",
    "href": "posts/2023-09-09-01. classification.html#로지스틱-회귀모형",
    "title": "01. Classification",
    "section": "1. 로지스틱 회귀모형",
    "text": "1. 로지스틱 회귀모형\n- 로지스틱 모형은 target 변수인 \\(y\\)에 대한 직접적 모형화가 아닌 \\(y\\)가 특정 법주에 포함될 확률을 모형화한다.\n\\[P(y=1 \\,|\\, \\bf {X})\\]\n- 임계치(threshole)를 정하고 어떤 범주에 포함될 확률이 임계치보다 높으면 0 or 1로 예측하는 분류 모형이다. (이진분류에서!)\n\nmodel 1. 이진분류\nstep 1. \\(P(X)\\) : 0과 1사이의 값으로 예측해주는 모형화 작성 (로지스틱 함수)\n\\[P(X) = \\frac {\\exp (\\beta_0 + \\beta_{1}X)}{1+\\exp (\\beta_0 + \\beta_{1}X) } \\in  (0,1 )\\]\nstep 2. \\(\\frac{P(X)}{ 1- P(X)}\\) : odds, 배팅을 하는 분야에서 확률 대신 많이 쓰이는 측도\n\\[\\frac {P(X)}{ 1- P(X)} =  \\exp(\\beta_0 + \\beta_{1} X  ),\\quad  \\in (0,\\infty)\\]\nstep 3. \\(\\log \\frac {P(X)}{1-P(X)}\\) : 이와 같은 식을 logit이라고 하며, 해당 함수를 선형회귀처럼 작성하면 다음과 같다.\n\\[\\log \\frac {P(X)}{1-P(X)}  = \\beta_0 + \\beta_1 X,\\quad \\in (-\\infty, \\infty)\\]\n\n\n모델 추정(이진 분류)\n- 반응변수는 범주형 변수이나 모형을 통해 예측된 값은 확률이므로 최소제곱법 등은 정당화 되기 어려움\n\n최대우도추정법(maximum likelihood estimation)으로 보통 추정한다.\n반응변수가 베르누이 (혹은 아항) 분포임을 이용하여 가능도함수를 기술함\n\n\\[L = \\prod_{i : y_i=1}p(x_i) \\prod_{i^{\\prime} : y_i^{\\prime} =0}(1-p(x_i)) \\]\n\n\\((\\hat {\\beta}_0, \\hat {\\beta}_1)\\) : 위 수식을 최대화 하는 추정치이다.\n\n\n\nmodel 2. 다중분류\n\\[\\log \\frac {P(X)}{1-P(X)}  = \\beta_0 + \\beta_1 X + \\dots \\beta_{p}X_{p},\\quad \\in (-\\infty, \\infty)\\]\n\\[p(X) = \\frac { \\beta_0 + \\beta_1 X + \\dots \\beta_{p}X_{p}}{1+exp\\,( \\beta_0 + \\beta_1 X + \\dots \\beta_{p}X_{p})},\\quad \\in (0,1)\\]",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#판별분석discriminant-analysis",
    "href": "posts/2023-09-09-01. classification.html#판별분석discriminant-analysis",
    "title": "01. Classification",
    "section": "2. 판별분석(discriminant analysis)",
    "text": "2. 판별분석(discriminant analysis)\n- 반응변수가 셋 이상의 범주를 가질 떄, 로지스틱 모형을 확장하여 위와 같이 고려할 수 있다.\n- 그러나 다른 대안들의 존재로 인해 이 경우 로지스틱 모형은 폭넓게 스이지는 않는다.\n- 대표적인 대안 중 하나는 선형판별분석이다.\n\n반응변수와 예측변수들의 결합분포에 기반한 방법\n\\(n\\)이작고 \\(X\\)의 분포가 정규분포에 가까울 때 판별분석의 성능이 로지스틱보다 좋다.\n\n- 베이즈 정리\n\n\\(k\\)번째 범주로부터 관측된 \\(X\\)의 분포를 \\(f_k(x)= P(X=x|Y =k) = P(X=x,Y =k)\\) 라 하고, \\(\\pi_k= P(Y=k)\\) 를 각 범주의 사전확률이라고 하면, 베이즈 정리에 의하여 다음을 얻는다.\n\n\\[P(Y=k | X=x) = \\frac{\\pi_k f_k(x)}{\\sum_{i=1}^{K} \\pi_{i}f_{i}(x)}\\]\n\n(1) LDA(Linear discriminant analysis)\n- \\(p=1, f_k(x)\\)가 정규분포임과 동시에 각 범주에 해당하는 분포의 분산은 동일하다 가정\n\n\\(p\\) 는 예측변수의 개수\n\n\\[X \\sim N(\\mu_k, \\sigma_k^{2})\\]\n- 조건부 확률 \\(P(Y=k | X=x))\\)를 최대화 시키는 \\(k\\)를 찾는 것은 아래의 판별함수를 최대화하는 \\(k\\)를 찾는 것이다.\n\n\\(\\hat{\\delta}_{k}\\) 를 최대화시키는 범주 \\(k\\)로 관측치를 할당.\n\n\\[\\delta_k(x) = x \\frac {\\mu_k}{\\sigma^2} - \\frac {\\mu_{k}^2}{2\\sigma^2}+ \\log \\pi_k\\]\n- \\(K=2\\)인 경우, 분류를 위한 경계치는\n\\[x = \\frac {\\mu_1+\\mu_2}{2}\\]\n\n\n\n- 또한, \\(p=1\\)인 경우, LDA는 다음과 같이 베이즈 분류기를 근사하게 된다.\n\\[\\hat {\\delta}_k(x) = x \\frac {\\hat {\\mu}_k}{\\hat{\\sigma}^2} - \\frac {\\hat{\\mu}_{k}^2}{2\\hat{\\sigma}^2}+ \\log \\hat{\\pi}_k\\]\n\\[\\hat {\\mu}_k = \\frac{1}{n_k} \\sum_{i : y_i=k} x_i\\]\n\\[\\hat {\\sigma}^2 = \\frac{1}{n-K} \\sum_{k=1}^K \\sum_{i:y_i = k} (x_i - \\hat {\\mu}_k)^2\\]\n\\[\\hat {P}(Y=k) = \\hat {\\pi}_k  = \\frac{n_k}{n}\\]\n- LDA의 linear라는 단어는 판별함수 \\(\\hat {\\delta}_k(x)\\)가 \\(x\\)의 선형함수로 표현된다는 사실로부터 유래한다.\n\nif, p&gt;1?\n- 예측변수가 다변량인 경우 \\(k\\)번째 범주에서 예측변수가 다변량 정규분포를 따른다는 가정으로부터 출발한다.\n\\[f_k(x) \\sim N(\\mu_k, \\Sigma)\\]\n- \\(p=1\\) 일 때와 마찬기지로 모든 범주에서 공분산 행렬 \\(\\sum\\)는 동일하다고 가정\n\\[\\delta_k(x) = x ^{\\top}{\\Sigma}^{-1} {\\mu_k}- \\frac {1}{2} \\mu_{k}^{\\top}{\\Sigma}^{-1}\\mu_k+ \\log \\pi_k\\]\n\n\n\n(2) QDA(Quadratic discriminant analysis)\n- LDA와 다르게 각 범주를 특정하는 정규분포의 분산에 이질성을 허용한다.\n\\[X \\sim N(\\mu_k, {\\Sigma}_k)\\]\n- 판별함수는 다음과 같다.\n\\[\\delta_k(x) = -\\frac{1}{2}(x-\\mu_k) ^{\\top}{\\Sigma}_{k}^{-1}(x-\\mu_k)- \\frac {1}{2}\\log |{\\Sigma}_k|\\log \\pi_k\\]",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#knnk-nearest-neighbors",
    "href": "posts/2023-09-09-01. classification.html#knnk-nearest-neighbors",
    "title": "01. Classification",
    "section": "3. KNN(K-nearest neighbors)",
    "text": "3. KNN(K-nearest neighbors)\n- 조건부 확률을 인접한 \\(K\\)개의 data points의 상대비율로 추정\n\\[P(y=j | X = x_0) = \\frac{1}{K} \\sum_{i\\in N_0} I(y_i=j)\\]\n\\[N_0  : x_0  \\text{와 가장 가까운} K \\text{개의 자료의 집합}\\]\n- 위 확률을 최대로 하는 \\(j\\)로 관측치를 분류\n- K의 선택이 분류기의 성능을 결정하는데 매우 핵심적인 역할을 수행한다,",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#summary-1",
    "href": "posts/2023-09-09-01. classification.html#summary-1",
    "title": "01. Classification",
    "section": "summary",
    "text": "summary\n- 범주가 2개일 때, LDA와 로지스틱모형은 선형적인 decision boundary를 생성한다는 측면에서 동일함\n- 각 범주의 분포가 정규분포로 잘 근사되는지 여부에 의해서 두 방식의 성능이 엇갈릴 수 있음\n- KNN은 decision boundary에 어떠한 가정도 하지 않음. 즉, decision boundary가 비선형인 경우 위 두 방식에 비해 우월성을 보임\n- QDA는 qudratic decision boundary를 설정한다는 면에서 KNN과 LDA 혹은 로지스틱의 중간쯤에 위치하는 방법으로 볼 수 있음\n\n모든 상황에서 항상 우월한 분류기는 없다",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#naive-bayes",
    "href": "posts/2023-09-09-01. classification.html#naive-bayes",
    "title": "01. Classification",
    "section": "4. Naive Bayes",
    "text": "4. Naive Bayes\n- 사실 LDA, QDA의 경우 \\(X\\)의 확률분포가 정규분포라고 추정하는 것은 어렵다.\n\n예측변수 \\(X_j\\) 간의 어떠한 연관성이 있을수가 있음. 즉 독립이 아님\n따라서 추정이 어려움, 독립이 아닐경우, 결합분포, 주변확률 분포 등등 사전, 사후 확률 계산시 고려해야할 사항들이 너무 많고 복잡함.\n그래서 나이브 베이즈에서는 각각의 클래스안에서 예측변수들은 서로 독립이다. 라는 가정에서 출발\n\\(k\\)번째 클래스 안에서 \\(X_j\\)에 대한 확률분포는 다음과 같다.\n\n\\[X_j|Y = k \\sim N(\\mu_{jk},\\sigma^{2}_{jk})\\]\n- 아래는 \\(k\\)번째 클래스의 확률분포이다.\n\\[f_k(x) = f_{k1}(x_1) \\times \\dots  \\times f_{kp}(x_p) \\]\n- 이제 사후 확률을 계산식을 살펴보자\n\\[P(Y=k|X=x ) = \\frac{\\pi_k \\times f_{k1}(x_1) \\times f_{k2}(x_2) \\times f_{kp}(x_p)}{\\sum_{i=1}^{k}\\pi_i \\times f_{i1}(x_1) \\times f_{i2}(x_2) \\times f_{ip}(x_p) }\\]\n- example : \\(\\pi_1= \\pi_2= 0.5\\)\n$K=1, ({11}(0.4) = 0.368, ,{12}(1.5) = 0.484, , _{13}(1) = 0.226) $\n$K=2, ({21}(0.4) = 0.030, ,{22}(1.5) = 0.130, , _{23}(1) = 0.616) $\n위 공식을 이용하여 각각에 대한 사후활률을 추정하면?\n\nk1= 0.5*0.368*0.484*0.226/(0.5*0.368*0.484*0.226+ 0.5*0.030*0.130*0.616)\nk2 = 0.5*0.030*0.130*0.616/(0.5*0.368*0.484*0.226+ 0.5*0.030*0.130*0.616)\n\nprint(f\"P(y=1) ={k1 : .3f}, P(y=2) ={k2 : .3f} \")\n\nP(y=1) = 0.944, P(y=2) = 0.056 \n\n\n\n나이브 베이즈 분류기는 확실이 LDA, QDA보다 계산이 간단하고 모델링 시 더 빠르게 수행될 것 같음",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#import",
    "href": "posts/2023-09-09-01. classification.html#import",
    "title": "01. Classification",
    "section": "import",
    "text": "import\n\n\nCode\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.pyplot import subplots\nimport statsmodels.api as sm\nfrom ISLP import load_data\nfrom ISLP.models import (ModelSpec as MS,\nsummarize)\n\nfrom ISLP import confusion_table\nfrom ISLP.models import contrast\nfrom sklearn.discriminant_analysis import \\\n(LinearDiscriminantAnalysis as LDA,\nQuadraticDiscriminantAnalysis as QDA)\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#data-load",
    "href": "posts/2023-09-09-01. classification.html#data-load",
    "title": "01. Classification",
    "section": "data load",
    "text": "data load\n\nSmarket = load_data('Smarket')\nSmarket.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1250 entries, 0 to 1249\nData columns (total 9 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Year       1250 non-null   int64  \n 1   Lag1       1250 non-null   float64\n 2   Lag2       1250 non-null   float64\n 3   Lag3       1250 non-null   float64\n 4   Lag4       1250 non-null   float64\n 5   Lag5       1250 non-null   float64\n 6   Volume     1250 non-null   float64\n 7   Today      1250 non-null   float64\n 8   Direction  1250 non-null   object \ndtypes: float64(7), int64(1), object(1)\nmemory usage: 88.0+ KB\n\n\n\nSmarket.head()\n\n\n\n\n\n\n\n\n\nYear\nLag1\nLag2\nLag3\nLag4\nLag5\nVolume\nToday\nDirection\n\n\n\n\n0\n2001\n0.381\n-0.192\n-2.624\n-1.055\n5.010\n1.1913\n0.959\nUp\n\n\n1\n2001\n0.959\n0.381\n-0.192\n-2.624\n-1.055\n1.2965\n1.032\nUp\n\n\n2\n2001\n1.032\n0.959\n0.381\n-0.192\n-2.624\n1.4112\n-0.623\nDown\n\n\n3\n2001\n-0.623\n1.032\n0.959\n0.381\n-0.192\n1.2760\n0.614\nUp\n\n\n4\n2001\n0.614\n-0.623\n1.032\n0.959\n0.381\n1.2057\n0.213\nUp\n\n\n\n\n\n\n\n\n- 해당 데이터는 2001년 부터 2005년까지 주식 데이터이다.\n\nYear는 해당 데이터가 관측된 년도\nLag1은 하루 전의 수익률\nLag2는 이틀 전의 수익률\n이렇게 Lag5까지 5일 전까지의 수익률을 가지고 있다.\nVolume은 하루에 평균적으로 몇 주가 거래되었는지\nToday는 오늘의 수익률\nDirection은 오늘 시장이 Up인지 Down인지 (target)",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#correlation",
    "href": "posts/2023-09-09-01. classification.html#correlation",
    "title": "01. Classification",
    "section": "correlation",
    "text": "correlation\n\nSmarket.select_dtypes(\"number\").corr()\n\n\n\n\n\n\n\n\n\nYear\nLag1\nLag2\nLag3\nLag4\nLag5\nVolume\nToday\n\n\n\n\nYear\n1.000000\n0.029700\n0.030596\n0.033195\n0.035689\n0.029788\n0.539006\n0.030095\n\n\nLag1\n0.029700\n1.000000\n-0.026294\n-0.010803\n-0.002986\n-0.005675\n0.040910\n-0.026155\n\n\nLag2\n0.030596\n-0.026294\n1.000000\n-0.025897\n-0.010854\n-0.003558\n-0.043383\n-0.010250\n\n\nLag3\n0.033195\n-0.010803\n-0.025897\n1.000000\n-0.024051\n-0.018808\n-0.041824\n-0.002448\n\n\nLag4\n0.035689\n-0.002986\n-0.010854\n-0.024051\n1.000000\n-0.027084\n-0.048414\n-0.006900\n\n\nLag5\n0.029788\n-0.005675\n-0.003558\n-0.018808\n-0.027084\n1.000000\n-0.022002\n-0.034860\n\n\nVolume\n0.539006\n0.040910\n-0.043383\n-0.041824\n-0.048414\n-0.022002\n1.000000\n0.014592\n\n\nToday\n0.030095\n-0.026155\n-0.010250\n-0.002448\n-0.006900\n-0.034860\n0.014592\n1.000000\n\n\n\n\n\n\n\n\n\nLag_i, todayt 간 상관계수는 거의 0에 가깝다.\n유일하게 의미가 있아보이는 상관관계는 Year, Volume로 계산된 \\(r\\)이 ‘0.539’ 이다.\n다시 말해서, 2001년부터 2005년까지, 하루 평균 거래량이 증가하고 있다.\n\n\nSmarket.plot( y=\"Volume\")",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "posts/2023-09-09-01. classification.html#model1.-logistic",
    "href": "posts/2023-09-09-01. classification.html#model1.-logistic",
    "title": "01. Classification",
    "section": "model1. Logistic",
    "text": "model1. Logistic\n- Lag1 ~ Lag5 까지의 변수로 금일 시장이 up인지 down인지 예측해보자.\n\n# step 1. x,y를 저장\nallvars = Smarket.columns.drop([\"Today\",\"Year\",\"Direction\"])\n\nX = MS(allvars).fit_transform(Smarket) \ny = Smarket.Direction == \"Up\"\n\n# step 2.  모형 적합\n\nglm = sm.GLM(y,X , family = sm.families.Binomial())\n\n# step 3. 모형에 대한 유의성 확인\nresults = glm.fit()\nresults.pvalues\n\nintercept    0.600700\nLag1         0.145232\nLag2         0.398352\nLag3         0.824334\nLag4         0.851445\nLag5         0.834998\nVolume       0.392404\ndtype: float64\n\n\n\n유의미한 변수가 한개도 없다..\n그나마 p-value가 낮은, lag1, lag2만 포함시켜보자\n\n- predict() : 데이터 집합을 인자로 전달해주지 않으면 훈련 데이터를 이용하여 예측을 수행\n\n# step 1. x,y를 저장\n\nX = MS([\"Lag1\",\"Lag2\"]).fit_transform(Smarket) \ny = Smarket.Direction == \"Up\"\n\n# step 2.  모형 적합\n\nglm = sm.GLM(y,X , family = sm.families.Binomial())\n\n# step 3. 모형에 대한 유의성 확인\nresults = glm.fit()\n\n\nprobs = results.predict()\n\nlabels = np.array([\"Down\"]*1250)\nlabels[probs &gt; 0.5] = \"Up\"\nlabel = [\"Up\",\"Down\"]\n\nconfusion_table(labels, Smarket.Direction)\n\n\n\n\n\n\n\n\nTruth\nDown\nUp\n\n\nPredicted\n\n\n\n\n\n\nDown\n114\n102\n\n\nUp\n488\n546\n\n\n\n\n\n\n\n\n\n데이터셋 분할\n- 2005년 이전을 train, 이후를 test로 전환\n\ntrain = (Smarket.Year &lt; 2005)\nSmarket_train = Smarket.loc[train]\nSmarket_test = Smarket.loc[-train]\n\nX_train, X_test = X.loc[train], X.loc[-train]\ny_train, y_test = y.loc[train], y.loc[-train]\n\n\n\n모델 적합\n\nglm_train = sm.GLM(y_train,\n                  X_train,\n                family=sm.families.Binomial())\n\nresults = glm_train.fit()\nprobs = results.predict(exog=X_test)\nlabels = np.array(['Down']*252)\n\nlabels[probs &gt;0.5] = 'Up'\n\n\nD = Smarket.Direction\nL_train, L_test = D.loc[train], D.loc[-train]\n\n\nnp.mean(labels == L_test)\n\n0.5595238095238095\n\n\n\nreport = classification_report(y_true = L_test, y_pred = labels,target_names=label,output_dict=True)\nresult_acc_logistic = pd.DataFrame({\"acc\" : [report[\"accuracy\"]],\n                             \"model\" : [\"로지스틱\"]})\nresult_acc_logistic\n\n\n\n\n\n\n\n\n\nacc\nmodel\n\n\n\n\n0\n0.559524\n로지스틱\n\n\n\n\n\n\n\n\n\nresult_logistic = pd.DataFrame(report).\\\n                                    eval(\"model = '로지스틱'\")[[\"Up\",\"model\"]].\\\n                                                reset_index().iloc[:-1,]\nresult_logistic\n\n\n\n\n\n\n\n\n\nindex\nUp\nmodel\n\n\n\n\n0\nprecision\n0.500000\n로지스틱\n\n\n1\nrecall\n0.315315\n로지스틱\n\n\n2\nf1-score\n0.386740\n로지스틱",
    "crumbs": [
      "Lecture",
      "Posts",
      "01. Classification"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISLP2023",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 10, 2023\n\n\n07. summary (1)\n\n\nGC \n\n\n\n\nSep 28, 2023\n\n\n06. net 설계 (2)\n\n\nstudy \n\n\n\n\nSep 26, 2023\n\n\n05. net 설계 (1)\n\n\nstudy \n\n\n\n\nSep 21, 2023\n\n\n04. 경사하강법 (2)\n\n\nstudy \n\n\n\n\nSep 19, 2023\n\n\n03. 경사하강법 (1)\n\n\nstudy \n\n\n\n\nSep 14, 2023\n\n\n02. tensorflow (2)\n\n\nstudy \n\n\n\n\nSep 12, 2023\n\n\n01. tensorflow (1)\n\n\nstudy \n\n\n\n\nSep 10, 2023\n\n\n01. Classification\n\n\nGC \n\n\n\n\nSep 9, 2023\n\n\n00. Linear Regression\n\n\nGC \n\n\n\n\nSep 3, 2023\n\n\n00. 단순선형회귀분석\n\n\nGC \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About me",
    "section": "contact",
    "text": "contact\n\nE-mail : rkdcjf8232@gmail.com",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "Education",
    "text": "Education\n\n전북대학교 통계학 학사(부전공 : 컴퓨터공학) | 2015.03 ~ 2021.02\n전북대학교 통계학 석사 | 2021.03 ~ 2023.02",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#certificate",
    "href": "about.html#certificate",
    "title": "About me",
    "section": "Certificate",
    "text": "Certificate\n\n사회조사분석사 2급\n데이터분석준전문가(ADsP)\nAICE Associate",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#skill",
    "href": "about.html#skill",
    "title": "About me",
    "section": "Skill",
    "text": "Skill\n\nR ⭐⭐⭐⭐\nPython ⭐⭐⭐⭐\nEXCEL ⭐⭐⭐⭐\nSPSS ⭐⭐⭐⭐\nSQL ⭐⭐⭐\nJAVA, C ⭐⭐",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#extracurricular-activities",
    "href": "about.html#extracurricular-activities",
    "title": "About me",
    "section": "Extracurricular Activities",
    "text": "Extracurricular Activities\n\n국민연금공단 빅데이터부 현장실습 | 2020. 03 ~ 2020. 06\n지역 문화산업 융복합 데이터 전문가 과정 | 과학기술정보통신부, 한국데이터산업진흥원 | 2021. 06 ~ 2021. 08\n빅데이터 혁신공유대학사업 서포터즈 |전북대학교 빅데이터 현신공유대학사업| 2021. 07. 01 ~ 2021. 10. 31\nKT AIVLE School DX Consultant Track | KT | 2023. 08. 08 ~ 2024. 01. 25",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#publication",
    "href": "about.html#publication",
    "title": "About me",
    "section": "Publication",
    "text": "Publication\n\n데이터 분석을 통한 지역별 고령친화도 시각화\n\n김영선, 강민구, 이강철 등 | 문화융복합아카이빙연구소 | 2021. 10 | 기록관리/보존\n\n핵심어 추출 및 데이터 증강기법을 이용한 텍스트 분류 모델 성능 개선\n\n이강철, 안정용 | 한국자료분석학회 | 한국자료분석학회 | 2022. 10 | 통계학",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#awards",
    "href": "about.html#awards",
    "title": "About me",
    "section": "Awards",
    "text": "Awards\n\n학회장상 | 한국통계학회 | 2023. 02. 22\nAIVLE Big Project Practical | KT | 2024. 01. 25",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#interest",
    "href": "about.html#interest",
    "title": "About me",
    "section": "Interest",
    "text": "Interest\n\nNLP\nAction Recognition, Object Detection\nData Science\nGrowth Hacking",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#my-blog",
    "href": "about.html#my-blog",
    "title": "About me",
    "section": "My blog",
    "text": "My blog\n 1. Lecture\n\nR for Data Science\nSpecial Topics in Data Visualization\nIntroduction to Python\nSpecial Topics in Big Data Analysis\nSpecial Topics in Machine Learning\n\n 2. Tableau\n\nTableau Practice\n\n 3. DX\n\nDX Consultant Education\n\n 4. Study\n\nISLP Study\nAlgorithm Study",
    "crumbs": [
      "Lecture",
      "**About me**"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html",
    "href": "posts/2023-09-09-00. Linear Regression.html",
    "title": "00. Linear Regression",
    "section": "",
    "text": "- 코랩환경에서 아래 순서대로 진행해야 ISLP 패키지 설치시 오류가 발생하지 않는다.\n\n드라이브 마운트\n현재 작업중인 경로로 이동\n패키지 import\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\ncd /content/drive/MyDrive/Colab Notebooks/ISLP/Linear Regression\n\n#pip install ISLP\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nfrom ISLP import load_data\n\nimport statsmodels.api as sm\n\nfrom statsmodels.stats.outliers_influence \\\nimport variance_inflation_factor as VIF\nfrom statsmodels.stats.anova import anova_lm\nfrom ISLP.models import (ModelSpec as MS,\nsummarize,poly)",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#표현1.-단순선형회귀",
    "href": "posts/2023-09-09-00. Linear Regression.html#표현1.-단순선형회귀",
    "title": "00. Linear Regression",
    "section": "표현1. 단순선형회귀",
    "text": "표현1. 단순선형회귀\n\\[\\hat {y} = \\hat {\\beta}_1x + \\hat {\\beta}_0\\]",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#표현-2-starstarstar",
    "href": "posts/2023-09-09-00. Linear Regression.html#표현-2-starstarstar",
    "title": "00. Linear Regression",
    "section": "표현 2 (\\(\\star\\star\\star\\))",
    "text": "표현 2 (\\(\\star\\star\\star\\))\n- 표현 2가 자주 쓰이니 잘 알아두자.\n\\[\\bf \\hat Y = X \\hat {\\boldsymbol{\\beta}} = \\begin{bmatrix}\n1  & x_1 \\\\ 1 & x_2  \\\\ \\dots & \\dots \\\\  1  & x_n\\end{bmatrix}\\begin{bmatrix} \\hat \\beta_0  \\\\ \\hat \\beta_1 \\end{bmatrix} \\]",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#잔차residual",
    "href": "posts/2023-09-09-00. Linear Regression.html#잔차residual",
    "title": "00. Linear Regression",
    "section": "잔차(residual)",
    "text": "잔차(residual)\n- \\(\\hat y_i = \\hat{\\beta_1} + \\hat {\\beta}_0x_i\\)는 개별 관측치 \\(x_i\\)가 주어졌을때 \\(i\\) 번째 \\(y\\)의 추정치이다.\n- 잔차는 표본으로부터 추정된 예측값에서 실제값의 차이로 다음과 같이 정의한다.\n\\[e_i = \\hat {y}_i - y_i,  \\quad e_i \\sim N(0,\\sigma^2)\\]\n- 그리고 책에서는 잔차제곱합을 다음과 같이 표현하니 눈에 익혀두자\n\\[RSS =\\sum_{i=1}^{n} e_i\\]",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#회귀계수-추정-1.-단순선형회귀",
    "href": "posts/2023-09-09-00. Linear Regression.html#회귀계수-추정-1.-단순선형회귀",
    "title": "00. Linear Regression",
    "section": "회귀계수 추정 1. 단순선형회귀",
    "text": "회귀계수 추정 1. 단순선형회귀\n- 잔차제곱합을 최소로하는 \\((\\beta_0, \\beta_1)\\)은 다음과 같은 추정치로 구해진다.\n\\[\\hat{\\beta}_1= \\frac{\\sum (x-\\bar x)(y-\\bar  y)}{\\sum (x-\\bar x)^2}\\]\n\\[\\hat {\\beta}_0 = \\bar y - \\hat {\\beta}_1 \\bar x\\]",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#회귀계수-추정-2.-일반적인-추정",
    "href": "posts/2023-09-09-00. Linear Regression.html#회귀계수-추정-2.-일반적인-추정",
    "title": "00. Linear Regression",
    "section": "회귀계수 추정 2. 일반적인 추정",
    "text": "회귀계수 추정 2. 일반적인 추정\n\\[\\boldsymbol{\\hat \\beta} = \\bf{(X^{\\top}X)^{-1}X^{\\top}y}\\]\n회귀계수 추정 및 벡터미분",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#회귀계수의-신뢰구간",
    "href": "posts/2023-09-09-00. Linear Regression.html#회귀계수의-신뢰구간",
    "title": "00. Linear Regression",
    "section": "회귀계수의 신뢰구간",
    "text": "회귀계수의 신뢰구간\n\n표준오차\n- 정의 : 추정값인 표본평균들과 참값인 모평균과의 표준적인 차이\n- 보통 모집단의 평균 \\(\\mu\\)를 추정할 때 추정치의 표준오차는 다음과 같이 정의된다.\n\\[\\text {Var} (\\hat {\\mu}) = \\text{SE}(\\hat {\\mu}) ^2= \\frac {\\sigma^2}{ n}\\]\n- 여기서 \\(\\sigma\\)는 표본(\\(y_i\\))으로 부터 산출된 표준편차이다. (standard deviation)\n- 회귀계수의 표준편차\n\\[\\text{SE} (\\hat {\\beta}_0)^2 = \\sigma^2 \\left [ \\frac 1n + \\frac {\\bar x^2}{\\sum (x-x_i)^2}\\right],\\quad \\text{SE} (\\hat {\\beta}_0)^2  = \\frac {\\sigma^2}{\\sum (x-\\bar x)^2}\\]\n\n\n회귀계수의 유의성 검정\n- 유의수준 \\(\\alpha\\) 각 회귀계수의 유의성 가설은 다음과 같다.\n\\[H_0 : \\beta_i  = 0, \\quad H_1 : \\beta_i \\neq 0\\]\n- 이 가설에 대한 95% 신뢰구간은?\n\\[\\beta_i \\pm 1.96 \\cdot \\text {SE} (\\hat {\\beta}_i)\\]\n- 사용되는 검정통계량은 \\(t-statistic\\)이다.\n\\[t = \\frac {\\hat {\\beta}_i - 0}{\\text{SE}(\\hat {\\beta_i})} \\]\n\n\n모델평가\n1 RSE : estimation of the standard deviation of \\(\\varepsilon\\) : 잔차의 평균\n\n\\(p\\) : 예측변수의 개수\n\n\\[\\text{RSE} = \\sqrt {\\frac {1}{n-(p+1)} RSS}\\]\n2 결정 계수 : 적합한 모델이 데이터를 얼마나 잘 설명하는지 해석적 측면\n\\[R^2 = \\frac {\\text{TSS} - \\text{RSS}}{\\text{TSS}} =  1-\\frac{\\text{RSS}}{\\text{TSS}}\\]\n\\[R^2_{adj} = \\frac {\\text{TSS} - \\text{RSS)}\\,/\\,(n-(p+1)}{\\text{TSS}\\,/\\,(n-1)} =  1-\\frac{\\text{RSS}}{\\text{TSS}}\\]\n\\[\\text{TSS} = \\sum (y_i-\\bar y)^2\\]\n\n\n전체 모델의 유의성 검정\n- 가설 설정\n\\[H_0 : \\beta_1 = \\beta_1 = \\dots \\beta_p = 0, \\quad H_1  : \\text{not} \\,\\,H_0\\]\n- \\(F-statistic\\)\n\\[F = \\frac {(TSS - RSS)\\,/\\,p}{RSS\\,/\\,(n-(p+1))}\\]\n\n\nsummary\n- 정리하다보니 순서가 조금 엉켰지만! 회귀분석 순서는 아래의 순서로 기억하자.\n\n전체 모델에 대한 유의성 검정\n개별 변수에 대한 유의성 검정\n결정계수값 확인\n잔차분석 (이번 블로그에서는 위 내용은 생략)",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#데이터-로드",
    "href": "posts/2023-09-09-00. Linear Regression.html#데이터-로드",
    "title": "00. Linear Regression",
    "section": "데이터 로드",
    "text": "데이터 로드\n- 아래의 데이터를 살펴보자.\n\nBoston data : 보스턴 시의 주택 가격에 대한 데이터 정보\n\ncrim : 자치시 별 1인당 범죄율\nzn : 25,000 평방피트르 초과하는 거주지역의 비율\nindus : 비소매상업지역이 점유하고 있는 토지의 비율\nchas : 찰스강에 대한 더미변수 (강의 경계에 위치한 경우는 1, 아니면 0)\nnos : 10ppm당 농축 일산화 질소\nrm : 주택 1가구당 평균 방의 개수\nage : 1940년 이전에 건축된 소유주택의 비율\ndis : 5개의 보스턴 직업센터까지의 접근성 지수\nrad : 방사형 도로까지의 접근성 지수\ntax : 10,000 달러 당 재산 세율\nptratio : 자치시별 학생/교사 비율\nlstat : 모집단의 하위 계층의 비율\nmedv : 본인 소유의 주택가격(중앙값) (단위 : $ 1,000)\n\n\n\nBoston = load_data(\"Boston\")\nBoston.columns\n#len(Boston.columns)\n\nIndex(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n       'ptratio', 'lstat', 'medv'],\n      dtype='object')",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#xy-생성",
    "href": "posts/2023-09-09-00. Linear Regression.html#xy-생성",
    "title": "00. Linear Regression",
    "section": "X,y 생성",
    "text": "X,y 생성\n\\[\\bf X = \\begin{bmatrix}\n1  & x_1 \\\\ 1 & x_2  \\\\ \\dots & \\dots \\\\  1  & x_n\\end{bmatrix}\\]\n\nlstat 변수를 예측변수로, medv변수를 반응변수로 사용\n\n\nX = pd.DataFrame({\"intercept\" : np.ones(Boston.shape[0]),\n                  \"lstat\" : Boston[\"lstat\"]})\ny = Boston[\"medv\"]\nX.head()\n\n\n\n\n\n\n\n\n\nintercept\nlstat\n\n\n\n\n0\n1.0\n4.98\n\n\n1\n1.0\n9.14\n\n\n2\n1.0\n4.03\n\n\n3\n1.0\n2.94\n\n\n4\n1.0\n5.33\n\n\n\n\n\n\n\n\n- OLS : Ordinary Least Squares의 약자로, 주어진 데이터에서 오차의 제곱을 최소화하는 \\(\\beta_i\\)를 추정한다.",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#모델-적합",
    "href": "posts/2023-09-09-00. Linear Regression.html#모델-적합",
    "title": "00. Linear Regression",
    "section": "모델 적합",
    "text": "모델 적합\n\nmodel = sm.OLS(y,X)\nresults = model.fit()\n\n\ns_result = summarize(results)\n\n\ns_result\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n\n\n\n\nintercept\n34.5538\n0.563\n61.415\n0.0\n\n\nlstat\n-0.9500\n0.039\n-24.528\n0.0\n\n\n\n\n\n\n\n\n- 적합된 모델을 해석하면 다음과 같다.\n\\[\\hat {\\text{medv}} = -0.95 \\times \\text{lstat} + 34\n.5538\\]",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#시각화",
    "href": "posts/2023-09-09-00. Linear Regression.html#시각화",
    "title": "00. Linear Regression",
    "section": "시각화",
    "text": "시각화\n\nx = Boston[\"lstat\"]\nyhat = results.predict()\n\n\n\nCode\nplt.plot(x,y,\"o\",label = r\"$(x,y)$\",alpha=0.3)\nplt.plot(x,yhat,\"--\",label = r\"$(x,\\hat {y})$\")\nplt.legend()",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#modelspec-starstarstar",
    "href": "posts/2023-09-09-00. Linear Regression.html#modelspec-starstarstar",
    "title": "00. Linear Regression",
    "section": "ModelSpec() (\\(\\star\\star\\star\\))",
    "text": "ModelSpec() (\\(\\star\\star\\star\\))\n- 우리는 앞서 다음과 같은 module을 import 했다\nfrom ISLP.models import (ModelSpec as MS,\nsummarize,poly)\n- ModelSpec이라는 모듈을 MS로 사용할 것으로 지칭\n- 이 모듈은 예측변수 \\(x\\)를 컴퓨터가 이해할 수 있게끔 변환해준다.\n- step1. 전달할 \\(x\\)를 다음과 같이 전달\n\ndesign = MS(['lstat'])\n\n- step2. 컴퓨터가 이해할 수 있는 형태에 맞게 \\(x\\)를 변환 \\(\\to\\) 주어진 \\(x\\)를 매트릭스 형태로 변환해줌\n\nX = design.fit_transform(Boston)\n\n\nX.head()\n\n\n\n\n\n\n\n\n\nintercept\nlstat\n\n\n\n\n0\n1.0\n4.98\n\n\n1\n1.0\n9.14\n\n\n2\n1.0\n4.03\n\n\n3\n1.0\n2.94\n\n\n4\n1.0\n5.33\n\n\n\n\n\n\n\n\n\n모델 적합\n\nmodel = sm.OLS(y, X)\nresults = model.fit()\n\n\n\n모델 요약\n\nreport = results.summary()\n\n\nreport.tables[0]\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\nmedv\nR-squared:\n0.544\n\n\nModel:\nOLS\nAdj. R-squared:\n0.543\n\n\nMethod:\nLeast Squares\nF-statistic:\n601.6\n\n\nDate:\nSat, 09 Sep 2023\nProb (F-statistic):\n5.08e-88\n\n\nTime:\n12:11:20\nLog-Likelihood:\n-1641.5\n\n\nNo. Observations:\n506\nAIC:\n3287.\n\n\nDf Residuals:\n504\nBIC:\n3295.\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n- 이런식으로 위의 표에 대한 데이터도 확인할 수 있음\n\nreport.tables[0].data\n\n[['Dep. Variable:', 'medv', '  R-squared:         ', '   0.544'],\n ['Model:', 'OLS', '  Adj. R-squared:    ', '   0.543'],\n ['Method:', 'Least Squares', '  F-statistic:       ', '   601.6'],\n ['Date:', 'Sat, 09 Sep 2023', '  Prob (F-statistic):', '5.08e-88'],\n ['Time:', '12:11:20', '  Log-Likelihood:    ', ' -1641.5'],\n ['No. Observations:', '   506', '  AIC:               ', '   3287.'],\n ['Df Residuals:', '   504', '  BIC:               ', '   3295.'],\n ['Df Model:', '     1', '                     ', ' '],\n ['Covariance Type:', 'nonrobust', '                     ', ' ']]\n\n\n- 추정된 회귀계수값 확인\n\nresults.params\n\nintercept    34.553841\nlstat        -0.950049\ndtype: float64\n\n\n\n\n모델 해석1 (모델의 유의성)\n\nreport.tables[0]\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\nmedv\nR-squared:\n0.544\n\n\nModel:\nOLS\nAdj. R-squared:\n0.543\n\n\nMethod:\nLeast Squares\nF-statistic:\n601.6\n\n\nDate:\nSat, 09 Sep 2023\nProb (F-statistic):\n5.08e-88\n\n\nTime:\n12:11:20\nLog-Likelihood:\n-1641.5\n\n\nNo. Observations:\n506\nAIC:\n3287.\n\n\nDf Residuals:\n504\nBIC:\n3295.\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n- 결정계수 (\\(R^2\\)) 값을 살펴보니 약 54%의 설명력을 가진 모델이다.\n- 또한, F통계량에 근거한 p-value 값을 살펴보았을 때 주어진 표본으로 부터 추출된 모형은 통계적으로 유의하다.\n\n\n모델 해석2 (예측변수의 유의성)\n\nreport.tables[1]\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nintercept\n34.5538\n0.563\n61.415\n0.000\n33.448\n35.659\n\n\nlstat\n-0.9500\n0.039\n-24.528\n0.000\n-1.026\n-0.874\n\n\n\n\n\n\n- lstat의 coef \\(\\to\\) 즉, 회귀계수에 대한 유의성 검정결과\n\np-value값을 살펴본 결과 유의수준 0.05에서 유의성을 만족한다. 따라서 lstat의 회귀계수는 통계적으로 유의하다.\n\n\n\n시각화\n\nyhat = results.predict()\nx = X[\"lstat\"]\n\n- 적합된 \\((x,\\hat y)\\)와 \\((x,y)\\)를 시각화한 결과 몇몇 이상치를 제외하고 잘 예측하고 있는것 같다.\n\n\nCode\nplt.plot(x,y,\"o\",label = r\"$(x,y)$\",alpha=0.3)\nplt.plot(x,yhat,\"--\",label = r\"$(x,\\hat {y})$\")\nplt.legend()",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/2023-09-09-00. Linear Regression.html#summary-lab",
    "href": "posts/2023-09-09-00. Linear Regression.html#summary-lab",
    "title": "00. Linear Regression",
    "section": "summary : Lab",
    "text": "summary : Lab\n- 구구절절 말이 많았지만, 회귀모형 적합 시 아래의 step을 기억하자.\n\n# step 0. import\nimport statsmodels.api as sm\nfrom ISLP.models import (ModelSpec as MS,\nsummarize,poly)\n\n# step 1. x, y를 저장\nx = data.columns.drop(\"target\") \ny = data[\"target\"]\n\n# step 2.  matrix 형태의 X 생성\nX = MS(final).fit_transform(data)\n\n# step 3. 최소제곱법(OLS)를 이용하여 모델을 적합하겠다고 선언\nmodel = sm.OLS(y,X)\n\n# step 4. 모형에 대한 유의성 확인\nmodel.fit().summary().tables[0]\n\n# step 5. 개별 회귀계수에 대한 유의성 확인\nmodel.fit().summary().tables[1]",
    "crumbs": [
      "Lecture",
      "Posts",
      "00. Linear Regression"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html",
    "title": "00. 단순선형회귀분석",
    "section": "",
    "text": "지도학습 : 우리가 무언가 예측하고자 하는 변수가 존재 (ex : 판매율, 주가 등등)\n\n회귀 : 예측하고자 하는 변수가 연속형 변수(오늘 소개하려는 단순선형회귀분석)\n분류 : 예측하고자 하는 변수가 범주형 변수(채무 이행, 불이행 문제)\n\n비지도학습 : 예측하고자 하는 타겟변수가 없고 주어진 변수들을 통해 성격이 유사한 녀석들끼리 그룹을 형성하게끔 만든다.",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#데이터-생성",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#데이터-생성",
    "title": "00. 단순선형회귀분석",
    "section": "데이터 생성",
    "text": "데이터 생성\n\n\nCode\nx   = np.linspace(20,38,1000)\nepsilon = np.random.normal(size=1000)\ny  =  10.2 + 2.2*x + epsilon\nyhat = 10.2+2.2*x\nplt.plot(x,y,\".\",label = \"실제 데이터\",alpha=0.3)\nplt.plot(x,yhat,\".\",label = \"목표 모형\",alpha=0.3)\nplt.legend()",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#최적의-beta를-구하는-방법-1",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#최적의-beta를-구하는-방법-1",
    "title": "00. 단순선형회귀분석",
    "section": "최적의 \\(\\beta\\)를 구하는 방법 1",
    "text": "최적의 \\(\\beta\\)를 구하는 방법 1\n\n구하고자 하는 법칙\n베타 추정치\n\n\\[\\hat {\\beta}_1 = \\frac {\\sum (x-\\bar x) (y -\\bar y)} {\\sum (x-\\bar x)^2}= \\frac{S_{xy}}{S_{xx}}\\]\n\\[\\hat {\\beta}_0 = \\bar {y} - \\hat{\\beta}_1\\bar{x}\\]\n\n\nCode\nn = len(x)\nSxy = sum((x-np.mean(x))*(y-np.mean(y)) )\nSxx = sum((x-np.mean(x))**2)\n\nbeta1 = Sxy/Sxx\n\nbeta0 =  np.mean(y) - beta1*np.mean(x)\n\nplt.plot(x,y,\".\",label = \"실제 데이터\",alpha=0.15)\nplt.plot(x,yhat,\".\",label = \"목표 모형\",alpha=1.0)\nplt.plot(x,beta1*x+beta0,\".\",label = \"내가 만든 예측 모형\",alpha=0.1)\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n구하고자 하는 법칙\n\n\\[\\hat{y} \\approx  2.2x + 10.2 \\]\n\nbeta1,beta0\n\n(2.201391988948589, 10.18755888066763)",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#최적의-beta를-구하는-방법-2-starstarstar",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#최적의-beta를-구하는-방법-2-starstarstar",
    "title": "00. 단순선형회귀분석",
    "section": "최적의 \\(\\beta\\)를 구하는 방법 2 (\\(\\star\\star\\star\\))",
    "text": "최적의 \\(\\beta\\)를 구하는 방법 2 (\\(\\star\\star\\star\\))\n- matrix 이용\n\\[\\hat {\\bf {\\beta}} = \\bf{(X^{\\top}X)^{-1}X^{\\top}Y}\\]\n\\[\\bf \\hat Y = X \\hat {\\boldsymbol{\\beta}} = \\begin{bmatrix}\n1  & x_{11}  & x_{12} &\\dots & x_{1p} \\\\ 1  & x_{21}  & x_{22} &\\dots & x_{2p}  \\\\ \\dots & \\dots \\\\  1  & x_{n1}  & x_{n2} &\\dots & x_{np}\\end{bmatrix}  \\,\\,\\begin{bmatrix} \\hat \\beta_0  \\\\ \\hat \\beta_1  \\\\ \\dots \\\\ \\beta_n \\end{bmatrix} \\]\n- X 생성\n\nX = pd.DataFrame({\"intercept\" :  np.ones(len(x)),\n                             \"x1\" : x})\n\nY = y.reshape(-1,1)\n\nbeta = np.linalg.inv(X.T @ X) @ X.T @Y\nbeta\n\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\n10.187559\n\n\n1\n2.201392\n\n\n\n\n\n\n\n\n\n\nCode\nplt.plot(x,y,\".\",label = \"실제 데이터\",alpha=0.06)\nplt.plot(x,yhat,\".\",label = \"목표 모형\",alpha=0.8)\nplt.plot(x,np.array(X) @ beta,\".\",label = \"내가 만든 예측 모형\",alpha=0.05)\nplt.legend()",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#예측-성능-평가",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#예측-성능-평가",
    "title": "00. 단순선형회귀분석",
    "section": "예측 성능 평가",
    "text": "예측 성능 평가\n\nnp.mean((y-yhat)**2)\n\n0.9182134409556464",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step-1.-전달할-x를-다음과-같이-전달",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step-1.-전달할-x를-다음과-같이-전달",
    "title": "00. 단순선형회귀분석",
    "section": "step 1. 전달할 x를 다음과 같이 전달",
    "text": "step 1. 전달할 x를 다음과 같이 전달\n\ndesign = MS([\"x1\"])",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step-2.-컴퓨터가-이해할-수-있는-형태에-맞게-bfx를-생성",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step-2.-컴퓨터가-이해할-수-있는-형태에-맞게-bfx를-생성",
    "title": "00. 단순선형회귀분석",
    "section": "step 2. 컴퓨터가 이해할 수 있는 형태에 맞게 \\(\\bf{X}\\)를 생성",
    "text": "step 2. 컴퓨터가 이해할 수 있는 형태에 맞게 \\(\\bf{X}\\)를 생성\n\n_X = design.fit_transform(X)\n\n\n_X\n\n\n\n\n\n\n\n\n\nintercept\nx1\n\n\n\n\n0\n1.0\n20.000000\n\n\n1\n1.0\n20.018018\n\n\n2\n1.0\n20.036036\n\n\n3\n1.0\n20.054054\n\n\n4\n1.0\n20.072072\n\n\n...\n...\n...\n\n\n995\n1.0\n37.927928\n\n\n996\n1.0\n37.945946\n\n\n997\n1.0\n37.963964\n\n\n998\n1.0\n37.981982\n\n\n999\n1.0\n38.000000\n\n\n\n\n1000 rows × 2 columns",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step3.-모델-적합",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step3.-모델-적합",
    "title": "00. 단순선형회귀분석",
    "section": "step3. 모델 적합",
    "text": "step3. 모델 적합\n\nmodel = sm.OLS(y, _X)\nresults = model.fit()",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step4.-결과-확인",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step4.-결과-확인",
    "title": "00. 단순선형회귀분석",
    "section": "step4. 결과 확인",
    "text": "step4. 결과 확인\n\nsummarize(results)\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n\n\n\n\nintercept\n10.1876\n0.172\n59.320\n0.0\n\n\nx1\n2.2014\n0.006\n377.663\n0.0\n\n\n\n\n\n\n\n\n\nreport = results.summary()\nreport\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\ny\nR-squared:\n0.993\n\n\nModel:\nOLS\nAdj. R-squared:\n0.993\n\n\nMethod:\nLeast Squares\nF-statistic:\n1.426e+05\n\n\nDate:\nTue, 05 Sep 2023\nProb (F-statistic):\n0.00\n\n\nTime:\n17:10:55\nLog-Likelihood:\n-1375.8\n\n\nNo. Observations:\n1000\nAIC:\n2756.\n\n\nDf Residuals:\n998\nBIC:\n2765.\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nintercept\n10.1876\n0.172\n59.320\n0.000\n9.851\n10.525\n\n\nx1\n2.2014\n0.006\n377.663\n0.000\n2.190\n2.213\n\n\n\n\n\n\nOmnibus:\n0.621\nDurbin-Watson:\n1.956\n\n\nProb(Omnibus):\n0.733\nJarque-Bera (JB):\n0.493\n\n\nSkew:\n0.004\nProb(JB):\n0.782\n\n\nKurtosis:\n3.108\nCond. No.\n167.\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step5.-결과-시각화",
    "href": "posts/study/2023-09-03-00. 단순선형회귀분석.html#step5.-결과-시각화",
    "title": "00. 단순선형회귀분석",
    "section": "step5. 결과 시각화",
    "text": "step5. 결과 시각화\n\nx = _X[\"x1\"]\nyhat = results.predict()\n\n\nplt.plot(x,y,\"o\",label = r\"$(x,y)$\",alpha=0.3)\nplt.plot(x,yhat,\"--\",label = r\"$(x,\\hat {y})$\")\nplt.legend()",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "00. 단순선형회귀분석"
    ]
  },
  {
    "objectID": "posts/study/2023-09-14-02. tensorflow (2).html",
    "href": "posts/study/2023-09-14-02. tensorflow (2).html",
    "title": "02. tensorflow (2)",
    "section": "",
    "text": "imports\n\nimport tensorflow as tf\nimport numpy as np\n\n\ntf.config.experimental.list_physical_devices('GPU')\n\n[]\n\n\n\n\n지난강의 보충\n- max, min, sum, mean\n\na= tf.constant([1.0,2.0,3.0,4.0])\na\n\n&lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)&gt;\n\n\n\nprint(min(a), max(a))\n\ntf.Tensor(1.0, shape=(), dtype=float32) tf.Tensor(4.0, shape=(), dtype=float32)\n\n\n\ntf.reduce_mean(a)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=2.5&gt;\n\n\n\nconcat, stack\n- 예제: (2,3,4,5) stack (2,3,4,5) -&gt; (?,?,?,?,?)\n\na = tf.reshape(tf.constant(range(2*3*4*5)),(2,3,4,5))\nb = -a\n\n\na\n\n&lt;tf.Tensor: shape=(2, 3, 4, 5), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3,   4],\n         [  5,   6,   7,   8,   9],\n         [ 10,  11,  12,  13,  14],\n         [ 15,  16,  17,  18,  19]],\n\n        [[ 20,  21,  22,  23,  24],\n         [ 25,  26,  27,  28,  29],\n         [ 30,  31,  32,  33,  34],\n         [ 35,  36,  37,  38,  39]],\n\n        [[ 40,  41,  42,  43,  44],\n         [ 45,  46,  47,  48,  49],\n         [ 50,  51,  52,  53,  54],\n         [ 55,  56,  57,  58,  59]]],\n\n\n       [[[ 60,  61,  62,  63,  64],\n         [ 65,  66,  67,  68,  69],\n         [ 70,  71,  72,  73,  74],\n         [ 75,  76,  77,  78,  79]],\n\n        [[ 80,  81,  82,  83,  84],\n         [ 85,  86,  87,  88,  89],\n         [ 90,  91,  92,  93,  94],\n         [ 95,  96,  97,  98,  99]],\n\n        [[100, 101, 102, 103, 104],\n         [105, 106, 107, 108, 109],\n         [110, 111, 112, 113, 114],\n         [115, 116, 117, 118, 119]]]], dtype=int32)&gt;\n\n\ncase1 (1,2,3,4,5) stack (1,2,3,4,5) –&gt; (2,2,3,4,5) # axis=0\n\n#shape=(2, 2, 3, 4, 5)은 5차원 배열이며, 배열의 구조를 다음과 같이 설명:\n# 2개의 큰 묶음이 있고, 각 큰 묶음 안에 2개의 작은 묶음이 있으며,\n# 각 작은 묶음 안에 3개의 작은 덩어리가 있으며, 각 작은 덩어리 안에 4개의 작은 묶음이 있으며,\n# 각 작은 묶음 안에 5개의 요소가 있다는 것을 의미\n\n\ntf.stack([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]]],\n\n\n        [[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]]]],\n\n\n\n       [[[[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]],\n\n\n        [[[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)&gt;\n\n\ncase2 (2,1,3,4,5) stack (2,1,3,4,5) –&gt; (2,2,3,4,5) # axis=1\n\ntf.stack([a,b],axis=1)\n\n&lt;tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]]],\n\n\n        [[[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]]],\n\n\n        [[[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)&gt;\n\n\ncase3 (2,3,1,4,5) stack (2,3,1,4,5) –&gt; (2,3,2,4,5) # axis=2\n\n#shape=(2, 3, 2, 4, 5)은 5차원 배열이며, 배열의 구조를 다음과 같이 설명:\n# 2개의 큰 묶음이 있고, 각 큰 묶음 안에 3개의 작은 묶음이 있으며,\n# 각 작은 묶음 안에 2개의 작은 덩어리가 있으며, 각 작은 덩어리 안에 4개의 작은 묶음이 있으며,\n# 각 작은 묶음 안에 5개의 요소가 있다는 것을 의미\n\n\ntf.stack([a,b],axis=2)\n\n&lt;tf.Tensor: shape=(2, 3, 2, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]]],\n\n\n        [[[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]]],\n\n\n        [[[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]]],\n\n\n        [[[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]]],\n\n\n        [[[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)&gt;\n\n\ncase4 (2,3,4,1,5) stack (2,3,4,1,5) –&gt; (2,3,4,2,5) # axis=3\n\ntf.stack([a,b],axis=-2)\n\n&lt;tf.Tensor: shape=(2, 3, 4, 2, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   0,   -1,   -2,   -3,   -4]],\n\n         [[   5,    6,    7,    8,    9],\n          [  -5,   -6,   -7,   -8,   -9]],\n\n         [[  10,   11,   12,   13,   14],\n          [ -10,  -11,  -12,  -13,  -14]],\n\n         [[  15,   16,   17,   18,   19],\n          [ -15,  -16,  -17,  -18,  -19]]],\n\n\n        [[[  20,   21,   22,   23,   24],\n          [ -20,  -21,  -22,  -23,  -24]],\n\n         [[  25,   26,   27,   28,   29],\n          [ -25,  -26,  -27,  -28,  -29]],\n\n         [[  30,   31,   32,   33,   34],\n          [ -30,  -31,  -32,  -33,  -34]],\n\n         [[  35,   36,   37,   38,   39],\n          [ -35,  -36,  -37,  -38,  -39]]],\n\n\n        [[[  40,   41,   42,   43,   44],\n          [ -40,  -41,  -42,  -43,  -44]],\n\n         [[  45,   46,   47,   48,   49],\n          [ -45,  -46,  -47,  -48,  -49]],\n\n         [[  50,   51,   52,   53,   54],\n          [ -50,  -51,  -52,  -53,  -54]],\n\n         [[  55,   56,   57,   58,   59],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [ -60,  -61,  -62,  -63,  -64]],\n\n         [[  65,   66,   67,   68,   69],\n          [ -65,  -66,  -67,  -68,  -69]],\n\n         [[  70,   71,   72,   73,   74],\n          [ -70,  -71,  -72,  -73,  -74]],\n\n         [[  75,   76,   77,   78,   79],\n          [ -75,  -76,  -77,  -78,  -79]]],\n\n\n        [[[  80,   81,   82,   83,   84],\n          [ -80,  -81,  -82,  -83,  -84]],\n\n         [[  85,   86,   87,   88,   89],\n          [ -85,  -86,  -87,  -88,  -89]],\n\n         [[  90,   91,   92,   93,   94],\n          [ -90,  -91,  -92,  -93,  -94]],\n\n         [[  95,   96,   97,   98,   99],\n          [ -95,  -96,  -97,  -98,  -99]]],\n\n\n        [[[ 100,  101,  102,  103,  104],\n          [-100, -101, -102, -103, -104]],\n\n         [[ 105,  106,  107,  108,  109],\n          [-105, -106, -107, -108, -109]],\n\n         [[ 110,  111,  112,  113,  114],\n          [-110, -111, -112, -113, -114]],\n\n         [[ 115,  116,  117,  118,  119],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)&gt;\n\n\ncase5 (2,3,4,5,1) stack (2,3,4,5,1) –&gt; (2,3,4,5,2) # axis=4\n\ntf.stack([a,b],axis=-1)\n\n&lt;tf.Tensor: shape=(2, 3, 4, 5, 2), dtype=int32, numpy=\narray([[[[[   0,    0],\n          [   1,   -1],\n          [   2,   -2],\n          [   3,   -3],\n          [   4,   -4]],\n\n         [[   5,   -5],\n          [   6,   -6],\n          [   7,   -7],\n          [   8,   -8],\n          [   9,   -9]],\n\n         [[  10,  -10],\n          [  11,  -11],\n          [  12,  -12],\n          [  13,  -13],\n          [  14,  -14]],\n\n         [[  15,  -15],\n          [  16,  -16],\n          [  17,  -17],\n          [  18,  -18],\n          [  19,  -19]]],\n\n\n        [[[  20,  -20],\n          [  21,  -21],\n          [  22,  -22],\n          [  23,  -23],\n          [  24,  -24]],\n\n         [[  25,  -25],\n          [  26,  -26],\n          [  27,  -27],\n          [  28,  -28],\n          [  29,  -29]],\n\n         [[  30,  -30],\n          [  31,  -31],\n          [  32,  -32],\n          [  33,  -33],\n          [  34,  -34]],\n\n         [[  35,  -35],\n          [  36,  -36],\n          [  37,  -37],\n          [  38,  -38],\n          [  39,  -39]]],\n\n\n        [[[  40,  -40],\n          [  41,  -41],\n          [  42,  -42],\n          [  43,  -43],\n          [  44,  -44]],\n\n         [[  45,  -45],\n          [  46,  -46],\n          [  47,  -47],\n          [  48,  -48],\n          [  49,  -49]],\n\n         [[  50,  -50],\n          [  51,  -51],\n          [  52,  -52],\n          [  53,  -53],\n          [  54,  -54]],\n\n         [[  55,  -55],\n          [  56,  -56],\n          [  57,  -57],\n          [  58,  -58],\n          [  59,  -59]]]],\n\n\n\n       [[[[  60,  -60],\n          [  61,  -61],\n          [  62,  -62],\n          [  63,  -63],\n          [  64,  -64]],\n\n         [[  65,  -65],\n          [  66,  -66],\n          [  67,  -67],\n          [  68,  -68],\n          [  69,  -69]],\n\n         [[  70,  -70],\n          [  71,  -71],\n          [  72,  -72],\n          [  73,  -73],\n          [  74,  -74]],\n\n         [[  75,  -75],\n          [  76,  -76],\n          [  77,  -77],\n          [  78,  -78],\n          [  79,  -79]]],\n\n\n        [[[  80,  -80],\n          [  81,  -81],\n          [  82,  -82],\n          [  83,  -83],\n          [  84,  -84]],\n\n         [[  85,  -85],\n          [  86,  -86],\n          [  87,  -87],\n          [  88,  -88],\n          [  89,  -89]],\n\n         [[  90,  -90],\n          [  91,  -91],\n          [  92,  -92],\n          [  93,  -93],\n          [  94,  -94]],\n\n         [[  95,  -95],\n          [  96,  -96],\n          [  97,  -97],\n          [  98,  -98],\n          [  99,  -99]]],\n\n\n        [[[ 100, -100],\n          [ 101, -101],\n          [ 102, -102],\n          [ 103, -103],\n          [ 104, -104]],\n\n         [[ 105, -105],\n          [ 106, -106],\n          [ 107, -107],\n          [ 108, -108],\n          [ 109, -109]],\n\n         [[ 110, -110],\n          [ 111, -111],\n          [ 112, -112],\n          [ 113, -113],\n          [ 114, -114]],\n\n         [[ 115, -115],\n          [ 116, -116],\n          [ 117, -117],\n          [ 118, -118],\n          [ 119, -119]]]]], dtype=int32)&gt;\n\n\n- 예제: (2,3,4), (2,3,4), (2,3,4)\n\na= tf.reshape(tf.constant(range(2*3*4)),(2,3,4))\nb= -a\nc= 2*a\n\n(예시1) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (6,3,4)\n\ntf.concat([a,b,c],axis=0)\n\n&lt;tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]],\n\n       [[  0,   2,   4,   6],\n        [  8,  10,  12,  14],\n        [ 16,  18,  20,  22]],\n\n       [[ 24,  26,  28,  30],\n        [ 32,  34,  36,  38],\n        [ 40,  42,  44,  46]]], dtype=int32)&gt;\n\n\n(예시2) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,9,4)\n\ntf.concat([a,b,c],axis=1)\n\n&lt;tf.Tensor: shape=(2, 9, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11],\n        [  0,   2,   4,   6],\n        [  8,  10,  12,  14],\n        [ 16,  18,  20,  22]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23],\n        [ 24,  26,  28,  30],\n        [ 32,  34,  36,  38],\n        [ 40,  42,  44,  46]]], dtype=int32)&gt;\n\n\n(예시3) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,12)\n\ntf.concat([a,b,c],axis=-1)\n\n&lt;tf.Tensor: shape=(2, 3, 12), dtype=int32, numpy=\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3,   0,   2,   4,   6],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7,   8,  10,  12,  14],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11,  16,  18,  20,  22]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15,  24,  26,  28,  30],\n        [ 16,  17,  18,  19, -16, -17, -18, -19,  32,  34,  36,  38],\n        [ 20,  21,  22,  23, -20, -21, -22, -23,  40,  42,  44,  46]]],\n      dtype=int32)&gt;\n\n\n(예시4) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (3,2,3,4)\n\ntf.stack([a,b,c],axis=0)   #3차원이 4차원이 됐으므로 stack 필요 #첫번째 자리에 축 끼워넣음\n\n&lt;tf.Tensor: shape=(3, 2, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  4,   5,   6,   7],\n         [  8,   9,  10,  11]],\n\n        [[ 12,  13,  14,  15],\n         [ 16,  17,  18,  19],\n         [ 20,  21,  22,  23]]],\n\n\n       [[[  0,  -1,  -2,  -3],\n         [ -4,  -5,  -6,  -7],\n         [ -8,  -9, -10, -11]],\n\n        [[-12, -13, -14, -15],\n         [-16, -17, -18, -19],\n         [-20, -21, -22, -23]]],\n\n\n       [[[  0,   2,   4,   6],\n         [  8,  10,  12,  14],\n         [ 16,  18,  20,  22]],\n\n        [[ 24,  26,  28,  30],\n         [ 32,  34,  36,  38],\n         [ 40,  42,  44,  46]]]], dtype=int32)&gt;\n\n\n(예시5) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,3,4)\n\ntf.stack([a,b,c],axis=1)\n\n&lt;tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  4,   5,   6,   7],\n         [  8,   9,  10,  11]],\n\n        [[  0,  -1,  -2,  -3],\n         [ -4,  -5,  -6,  -7],\n         [ -8,  -9, -10, -11]],\n\n        [[  0,   2,   4,   6],\n         [  8,  10,  12,  14],\n         [ 16,  18,  20,  22]]],\n\n\n       [[[ 12,  13,  14,  15],\n         [ 16,  17,  18,  19],\n         [ 20,  21,  22,  23]],\n\n        [[-12, -13, -14, -15],\n         [-16, -17, -18, -19],\n         [-20, -21, -22, -23]],\n\n        [[ 24,  26,  28,  30],\n         [ 32,  34,  36,  38],\n         [ 40,  42,  44,  46]]]], dtype=int32)&gt;\n\n\n(예시6) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,3,4)\n\ntf.stack([a,b,c],axis=2)\n\n&lt;tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  0,  -1,  -2,  -3],\n         [  0,   2,   4,   6]],\n\n        [[  4,   5,   6,   7],\n         [ -4,  -5,  -6,  -7],\n         [  8,  10,  12,  14]],\n\n        [[  8,   9,  10,  11],\n         [ -8,  -9, -10, -11],\n         [ 16,  18,  20,  22]]],\n\n\n       [[[ 12,  13,  14,  15],\n         [-12, -13, -14, -15],\n         [ 24,  26,  28,  30]],\n\n        [[ 16,  17,  18,  19],\n         [-16, -17, -18, -19],\n         [ 32,  34,  36,  38]],\n\n        [[ 20,  21,  22,  23],\n         [-20, -21, -22, -23],\n         [ 40,  42,  44,  46]]]], dtype=int32)&gt;\n\n\n(예시7) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,4,3)\n\ntf.stack([a,b,c],axis=-1)\n\n&lt;tf.Tensor: shape=(2, 3, 4, 3), dtype=int32, numpy=\narray([[[[  0,   0,   0],\n         [  1,  -1,   2],\n         [  2,  -2,   4],\n         [  3,  -3,   6]],\n\n        [[  4,  -4,   8],\n         [  5,  -5,  10],\n         [  6,  -6,  12],\n         [  7,  -7,  14]],\n\n        [[  8,  -8,  16],\n         [  9,  -9,  18],\n         [ 10, -10,  20],\n         [ 11, -11,  22]]],\n\n\n       [[[ 12, -12,  24],\n         [ 13, -13,  26],\n         [ 14, -14,  28],\n         [ 15, -15,  30]],\n\n        [[ 16, -16,  32],\n         [ 17, -17,  34],\n         [ 18, -18,  36],\n         [ 19, -19,  38]],\n\n        [[ 20, -20,  40],\n         [ 21, -21,  42],\n         [ 22, -22,  44],\n         [ 23, -23,  46]]]], dtype=int32)&gt;\n\n\n- 예제: (2,3,4) (4,3,4) \\(\\to\\) (6,3,4)\n\na=tf.reshape(tf.constant(range(2*3*4)),(2,3,4))   #3차원이 3차원 됐으니까 concat 사용\nb=tf.reshape(-tf.constant(range(4*3*4)),(4,3,4))\n\n\ntf.concat([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]],\n\n       [[-24, -25, -26, -27],\n        [-28, -29, -30, -31],\n        [-32, -33, -34, -35]],\n\n       [[-36, -37, -38, -39],\n        [-40, -41, -42, -43],\n        [-44, -45, -46, -47]]], dtype=int32)&gt;\n\n\n\ntf.concat([a,b],axis=1)    #디멘션이 다르므로 연산 불가능\n\nInvalidArgumentError: ignored\n\n\n\ntf.concat([a,b],axis=2)\n\nInvalidArgumentError: ignored\n\n\n- (2,2) @ (2,) 의 연산?\nnumpy\n\nnp.array([[1,0],[0,1]])\n\narray([[1, 0],\n       [0, 1]])\n\n\n\nnp.array([[1,0],[0,1]]) @ np.array([77,-88])   #뒤에 1이 생략된 게 아니라 계산될 때 알아서 벡터가 조절\n\n\nnp.array([77,-88]) @ np.array([[1,0],[0,1]])\n\narray([ 77, -88])\n\n\n\nnp.array([[1,0],[0,1]]) @ np.array([77,-88]).reshape(2,1)\n\narray([[ 77],\n       [-88]])\n\n\n\nnp.array([77,-88]).reshape(2,1) @ np.array([[1,0],[0,1]])     #벡터를 2, 1로 선언했기 때문에 디멘션이 맞지 않음\n\nValueError: ignored\n\n\n\nnp.array([77,-88]).reshape(1,2) @ np.array([[1,0],[0,1]])\n\narray([[ 77, -88]])\n\n\ntensorflow\n\nI = tf.constant([[1.0,0.0],[0.0,1.0]])\nx = tf.constant([77.0,-88.0])\n\n\nI @ x   #디멘션 맞지 않아서 계산 안됨\n\nInvalidArgumentError: ignored\n\n\n\nx @ I\n\nInvalidArgumentError: ignored\n\n\n\nI @ tf.reshape(x,(2,1))\n\n&lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy=\narray([[ 77.],\n       [-88.]], dtype=float32)&gt;\n\n\n\ntf.reshape(x,(1,2)) @ I\n\n&lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 77., -88.]], dtype=float32)&gt;\n\n\n\n\n\n\ntf.Variable\n\n선언\n- tf.Variable()로 선언\n\ntf.Variable([1,2,3,4])     #V대문자 주의 #int형 float형 차이\n\n&lt;tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;\n\n\n\ntf.Variable([1.0,2.0,3.0,4.0])\n\n&lt;tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)&gt;\n\n\n- tf.constant() 선언후 변환\n\ntf.Variable(tf.constant([1,2,3,4]))   #원하는대로 자유롭게 변환 가능\n\n&lt;tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;\n\n\n- np 등으로 선언후 변환\n\ntf.Variable(np.array([1,2,3,4]))\n\n&lt;tf.Variable 'Variable:0' shape=(4,) dtype=int64, numpy=array([1, 2, 3, 4])&gt;\n\n\n\n\n타입\n\ntype(tf.Variable([1,2,3,4]))\n\n\n\n인덱싱\n\na=tf.Variable([1,2,3,4])\na\n\n&lt;tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;\n\n\n\na[:2]\n\n&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)&gt;\n\n\n\n\n연산가능\n\na=tf.Variable([1,2,3,4])\nb=tf.Variable([-1,-2,-3,-4])\n\n\na+b\n\n&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)&gt;\n\n\n\ntype(a)    #a=-b로 선언하면 형식변함\n\ntensorflow.python.ops.resource_variable_ops.ResourceVariable\n\n\n\ntype(a+b)   #더하면 형식 변하는 것을 볼 수 있음\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n\ntf.Variable도 쓰기 불편함\n\ntf.Variable([1,2])+tf.Variable([3.14,3.14])   #알아서 형 바꿔주는 거 안됨\n\nInvalidArgumentError: ignored\n\n\n\n\ntnp의 은총도 일부만 가능\n\nimport tensorflow.experimental.numpy as tnp\ntnp.experimental_enable_numpy_behavior()\n\n- 알아서 형 변환\n\ntf.Variable([1,2])+tf.Variable([3.14,3.14])\n\n&lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([4.1400001, 5.1400001])&gt;\n\n\n- .reshape 메소드\n\ntf.Variable([1,2,3,4]).reshape(2,2)\n#tf.constant([1,2,3,4]).reshape(2,2)  이거는 되는데 위에는 안됨\n\nAttributeError: ignored\n\n\n\n\n대부분의 동작은 tf.constant랑 큰 차이를 모르겠음\n- tf.concat\n\na= tf.Variable([[1,2],[3,4]])\nb= tf.Variable([[-1,-2],[-3,-4]])\ntf.concat([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[ 1,  2],\n       [ 3,  4],\n       [-1, -2],\n       [-3, -4]], dtype=int32)&gt;\n\n\n- tf.stack\n\na= tf.Variable([[1,2],[3,4]])     #stack이라 2차원으로 변하는 것 볼 수 있음\nb= tf.Variable([[-1,-2],[-3,-4]])\ntf.stack([a,b],axis=0)\n\n&lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\narray([[[ 1,  2],\n        [ 3,  4]],\n\n       [[-1, -2],\n        [-3, -4]]], dtype=int32)&gt;\n\n\n\n\n변수값변경가능(?)\n\na = 1\nid(a)\n\n133568373915888\n\n\n\na = 456\nid(a)\n\n133565694930256\n\n\n\na= tf.Variable([1,2,3,4])\nid(a)\n\n133565694988048\n\n\n\na.assign_add([-1,-2,-3,-4])    #주소값 똑같음 - 편집\nid(a)\n\n133565694988048\n\n\n\n\n요약\n- tf.Variable()로 만들어야 하는 뚜렷한 차이는 모르겠음.\n- 애써 tf.Variable()로 만들어도 간단한연산을 하면 그 결과는 tf.constant()로 만든 오브젝트와 동일해짐.\n\n\n\n미분\n\n모티브\n- 예제: 컴퓨터를 이용하여 \\(x=2\\)에서 \\(y=3x^2\\)의 접선의 기울기를 구해보자.\n(손풀이)\n\\[\\frac{dy}{dx}=6x\\]\n이므로 \\(x=2\\)를 대입하면 12이다.\n(컴퓨터를 이용한 풀이)\n단계1\n\nx1=2\ny1= 3*x1**2\n\n\nx2=2+0.000000001\ny2= 3*x2**2\n\n\n(y2-y1)/(x2-x1)\n\n12.0\n\n\n단계2\n\ndef f(x):\n    return(3*x**2)\n\n\nf(3)\n\n27\n\n\n\ndef d(f,x):\n    return (f(x+0.000000001)-f(x))/0.000000001\n\n\nd(f,2)\n\n12.000000992884452\n\n\n단계3\n\nd(lambda x: 3*x**2 ,2)    #함수 계속 선언하는 것 귀찮\n\n12.000000992884452\n\n\n\nd(lambda x: x**2 ,0)\n\n1e-09\n\n\n단계4\n\\[f(x,y)= x^2 +3y\\]\n\ndef f(x,y):\n    return(x**2 +3*y)\n\n\nd(f,(2,3))    #잘 구해주는 패키지를 이용하자\n\nTypeError: ignored\n\n\n\n\ntf.GradientTape() 사용방법\n- 예제1: \\(x=2\\)에서 \\(y=3x^2\\)의 도함수값을 구하라.\n\nx=tf.Variable(2.0)        #미분하고 싶은 변수를 variable\na=tf.constant(3.0)\n\n\nmytape=tf.GradientTape() #기울기 기록?\nmytape.__enter__() # 기록 시작\ny=a*x**2 # y=ax^2 = 3x^2\nmytape.__exit__(None,None,None) # 기록 끝\n\n\nmytape.gradient(y,x) # y를 x로 미분하라.\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=12.0&gt;\n\n\n- 예제2: 조금 다른예제\n\nx=tf.Variable(2.0)\n#a=tf.constant(3.0)\n\nmytape=tf.GradientTape()\nmytape.__enter__() # 기록 시작\na=(x/2)*3 ## a=(3/2)x\ny=a*x**2  ## y=ax^2 = (3/2)x^3\nmytape.__exit__(None,None,None) # 기록 끝\n\nmytape.gradient(y,x) # y를 x로 미분하라.\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt;\n\n\n\\[a=\\frac{3}{2}x\\] \\[y=ax^2=\\frac{3}{2}x^3\\]\n\\[\\frac{dy}{dx}=\\frac{3}{2} 3x^2\\]\n\n3/2*3*4\n\n18.0\n\n\n- 테이프의 개념 (\\(\\star\\))\n(상황)\n우리가 어려운 미분계산을 컴퓨터에게 부탁하는 상황임. (예를들면 \\(y=3x^2\\)) 컴퓨터에게 부탁을 하기 위해서는 연습장(=테이프)에 \\(y=3x^2\\)이라는 수식을 써서 보여줘야하는데 이때 컴퓨터에게 target이 무엇인지 그리고 무엇으로 미분하고 싶은 것인지를 명시해야함.\n\nmytape = tf.GradientTape(): tf.GradientTape()는 연습장을 만드는 명령어, 만들어진 연습장을 mytape라고 이름을 붙인다.\nmytape.__enter__(): 만들어진 공책을 연다 (=기록할수 있는 상태로 만든다)\na=x/2*3; y=a*x**2: 컴퓨터에게 전달할 수식을 쓴다\nmytape.__exit__(None,None,None): 공책을 닫는다.\nmytape.gradient(y,x): \\(y\\)를 \\(x\\)로 미분하라는 메모를 남기고 컴퓨터에게 전달한다.\n\n- 예제3: 연습장을 언제 열고 닫을지 결정하는건 중요하다.\n\nx=tf.Variable(2.0)\na=(x/2)*3 ## a=(3/2)x\n\nmytape=tf.GradientTape()\nmytape.__enter__() # 기록 시작\ny=a*x**2  ## y=ax^2 = (3/2)x^3\nmytape.__exit__(None,None,None) # 기록 끝\n\nmytape.gradient(y,x) # y를 x로 미분하라.\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=12.0&gt;\n\n\n- 예제4: with문과 함께 쓰는 tf.GradientTape()\n\nx=tf.Variable(2.0)\na=(x/2)*3\n\n\nwith tf.GradientTape() as mytape:\n    ## with문 시작\n    y=a*x**2\n    ## with문 끝\n\n\nmytape.gradient(y,x) # y를 x로 미분하라.\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=12.0&gt;\n\n\n(문법해설)\n아래와 같이 쓴다.\nwith expression as myname:\n    ## with문 시작: myname.__enter__()\n    blabla ~\n    yadiyadi !!\n    ## with문 끝: myname.__exit__()\n\nexpression 의 실행결과 오브젝트가 생성, 생성된 오브젝트는 myname라고 이름붙임. 이 오브젝트는 .__enter__()와 .__exit__()를 숨겨진 기능으로 포함해야 한다.\nwith문이 시작되면서 myname.__enter__()이 실행된다.\n블라블라와 야디야디가 실행된다.\nwith문이 종료되면서 myname.__exit__()이 실행된다.\n\n- 예제5: 예제2를 with문과 함께 구현\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape() as mytape:\n    a=(x/2)*3 ## a=(3/2)x\n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\nmytape.gradient(y,x) # y를 x로 미분하라.\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt;\n\n\n- 예제6: persistent = True\n(관찰1)\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape() as mytape:\n    a=(x/2)*3 ## a=(3/2)x\n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nmytape.gradient(y,x) # 2번이상 실행해서 에러를 관측하라 #persistent=True로 주면 2번 이상 실행해도 그대로 실행됨\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt;\n\n\n(관찰2)\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape(persistent=True) as mytape:\n    a=(x/2)*3 ## a=(3/2)x\n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nmytape.gradient(y,x) # 2번이상실행해도 에러가 나지않음\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt;\n\n\n- 예제7: watch\n(관찰1)\n\nx=tf.constant(2.0)   #constant로 실행했을 때\n\nwith tf.GradientTape(persistent=True) as mytape:\n    a=(x/2)*3 ## a=(3/2)x\n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\nNone\n\n\n(관찰2)\n\nx=tf.constant(2.0)\nwith tf.GradientTape(persistent=True) as mytape:\n    mytape.watch(x) # watch이용해서 수동감시 = variable과 같은 형태로\n    a=(x/2)*3 ## a=(3/2)x\n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n\ntf.GradientTape?\n\n(관찰3)\n\nx=tf.Variable(2.0)\nwith tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: # 자동감시 모드 해제\n    a=(x/2)*3 ## a=(3/2)x\n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\nNone\n\n\n(관찰4)\n\nx=tf.Variable(2.0)   #한다\nwith tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: # 자동감시 모드 해제 #안한다\n    mytape.watch(x) #한다\n    a=(x/2)*3 ## a=(3/2)x\n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n(관찰5)\n\nx=tf.Variable(2.0)\nwith tf.GradientTape(persistent=True) as mytape:\n    mytape.watch(x)\n    a=(x/2)*3 ## a=(3/2)x\n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n- 예제9: 카페예제로 돌아오자.\n- 예제10: 카페예제의 매트릭스 버전\n- 예제11: 위의 예제에서 이론적인 \\(\\boldsymbol{\\beta}\\)의 최적값을 찾아보고 (즉 \\(\\hat{\\boldsymbol{\\beta}}\\)을 찾고) 그곳에서 loss의 미분을 구하라. 구한결과가 \\(\\begin{bmatrix}0 \\\\ 0 \\end{bmatrix}\\) 임을 확인하라.",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "02. tensorflow (2)"
    ]
  },
  {
    "objectID": "posts/study/2023-09-21-04. 경사하강법 (2).html",
    "href": "posts/study/2023-09-21-04. 경사하강법 (2).html",
    "title": "04. 경사하강법 (2)",
    "section": "",
    "text": "import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow.experimental.numpy as tnp\ntnp.experimental_enable_numpy_behavior()",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "04. 경사하강법 (2)"
    ]
  },
  {
    "objectID": "posts/study/2023-09-21-04. 경사하강법 (2).html#sgd-확률적-경사하강법",
    "href": "posts/study/2023-09-21-04. 경사하강법 (2).html#sgd-확률적-경사하강법",
    "title": "04. 경사하강법 (2)",
    "section": "SGD : 확률적 경사하강법",
    "text": "SGD : 확률적 경사하강법\n\nbeta_hat = tf.Variable([-5.0,10.0]) ## 초기값 셋\nalpha = 0.1\nopt = tf.keras.optimizers.SGD(alpha) ## 경사하강법 종류 선언\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape:\n        yhat = X@beta_hat\n        loss = (y-yhat).T @ (y-yhat) / N\n    slope = tape.gradient(loss,beta_hat)\n    opt.apply_gradients( [(slope,beta_hat),(slope,beta_hat)] )\n\n\nbeta_hat\n\n&lt;tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([2.5205617, 3.9241781], dtype=float32)&gt;",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "04. 경사하강법 (2)"
    ]
  },
  {
    "objectID": "posts/study/2023-09-21-04. 경사하강법 (2).html#sgd-opt.minimize",
    "href": "posts/study/2023-09-21-04. 경사하강법 (2).html#sgd-opt.minimize",
    "title": "04. 경사하강법 (2)",
    "section": "SGD + opt.minimize",
    "text": "SGD + opt.minimize\n- opt.minimize \\(\\to\\) slope + beta_assign_sub\n- 셋팅\n\ny=y.reshape(N,1)\nX.shape,y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\n\n- loss 함수 정의\n\ndef loss_fn():\n    return (y-X@beta_hat).T @ (y-X@beta_hat)/N\n\n\nalpha=0.1\nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000):\n    opt.minimize(loss_fn,[beta_hat]) # 미분 + update\n\n\nbeta_hat\n\n&lt;tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.52055998],\n       [3.92418141]])&gt;",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "04. 경사하강법 (2)"
    ]
  },
  {
    "objectID": "posts/study/2023-09-21-04. 경사하강법 (2).html#netstarstarstar",
    "href": "posts/study/2023-09-21-04. 경사하강법 (2).html#netstarstarstar",
    "title": "04. 경사하강법 (2)",
    "section": "net(\\(\\star\\star\\star\\))",
    "text": "net(\\(\\star\\star\\star\\))\n\nN = 200\nalpha=0.1\nopt=tf.optimizers.SGD(alpha) ## 옵티마이저의 선택\n\n\\[y = ax +b\\]\n\\[y = X\\beta\\]\n\n## 포인트코드1: 네트워크 생성\nnet = tf.keras.Sequential() ## step1. net을 뭐 순차적으로 만들겠다.\n\n## 포인트코드2: 네트워크의 아키텍처 설계\nnet.add(tf.keras.layers.Dense(1,input_shape=(2,),use_bias=False))\n\n## 포인트코드3: 네트워크 컴파일 = 손실함수 + 옵티마이저\nnet.compile(opt,loss=tf.losses.MeanSquaredError())\n\n\n## 포인트코드4: 미분 & update\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N)\n\n&lt;keras.src.callbacks.History at 0x7bae8de924d0&gt;\n\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense_1/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5205722],\n        [3.924159 ]], dtype=float32)&gt;]\n\n\n\nplt.plot(x,y, \".r\",alpha= 0.3)\nplt.plot(x,2.5205722 + 3.924159*x, \".b\",alpha= 0.3)\n\n\n\n\n\n\n\n\n\nnet.summary()\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_1 (Dense)             (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2 (8.00 Byte)\nTrainable params: 2 (8.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "04. 경사하강법 (2)"
    ]
  },
  {
    "objectID": "posts/study/2023-09-28-06. net 설계 (2) .html",
    "href": "posts/study/2023-09-28-06. net 설계 (2) .html",
    "title": "06. net 설계 (2)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-ws3T1xD-bBU46dtduUlwmP\n\n\n\nimports\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n\n\npiece-wise linear regression\nmodel: \\(y_i=\\begin{cases} x_i +0.3\\epsilon_i & x\\leq 0 \\\\ 3.5x_i +0.3\\epsilon_i & x&gt;0 \\end{cases}\\)\n\nnp.random.seed(43052)\nN=100\nx = np.linspace(-1,1,N)\nlamb = lambda x: x*1+np.random.normal()*0.3 if x&lt;0 else x*3.5+np.random.normal()*0.3 \ny= np.array(list(map(lamb,x)))\ny\n\narray([-0.88497385, -0.65454563, -0.61676249, -0.84702584, -0.84785569,\n       -0.79220455, -1.3777105 , -1.27341781, -1.41643729, -1.26404671,\n       -0.79590224, -0.78824395, -0.86064773, -0.52468679, -1.18247354,\n       -0.29327295, -0.69373049, -0.90561768, -1.07554911, -0.7225404 ,\n       -0.69867774, -0.34811037,  0.11188474, -1.05046296, -0.03840085,\n       -0.38356861, -0.24299798, -0.58403161, -0.20344022, -0.13872303,\n       -0.529586  , -0.27814478, -0.10852781, -0.38294596,  0.02669763,\n       -0.23042603, -0.77720364, -0.34287396, -0.04512022, -0.30180793,\n       -0.26711438, -0.51880349, -0.53939672, -0.32052379, -0.32080763,\n        0.28917092,  0.18175206, -0.48988124, -0.08084459,  0.37706178,\n        0.14478908,  0.07621827, -0.071864  ,  0.05143365,  0.33932009,\n       -0.35071776,  0.87742867,  0.51370399,  0.34863976,  0.55855514,\n        1.14196717,  0.86421076,  0.72957843,  0.57342304,  1.54803332,\n        0.98840018,  1.11129366,  1.42410801,  1.44322465,  1.25926455,\n        1.12940772,  1.46516829,  1.16365096,  1.45560853,  1.9530553 ,\n        2.45940445,  1.52921129,  1.8606463 ,  1.86406718,  1.5866523 ,\n        1.49033473,  2.35242686,  2.12246412,  2.41951931,  2.43615052,\n        1.96024441,  2.65843789,  2.46854394,  2.76381882,  2.78547462,\n        2.56568465,  3.15212157,  3.11482949,  3.17901774,  3.31268904,\n        3.60977818,  3.40949166,  3.30306495,  3.74590922,  3.85610433])\n\n\n\nplt.plot(x,y,'.')\n\n\n\n\n\n\n\n\n\n풀이1: 단순회귀모형을 이용하여 적합\n\nx= x.reshape(N,1)\ny= y.reshape(N,1) \n\n\nnet = tf.keras.Sequential() \nnet.add(tf.keras.layers.Dense(1)) \nnet.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\nnet.fit(x,y,batch_size=N,epochs=1000,verbose=0) # verbose : loss값이 출력되지 않음 # numpy로 해도 돌아감\n\n2022-04-18 11:40:03.840482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n\n\n&lt;keras.callbacks.History at 0x7f3b7d0bf670&gt;\n\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[2.2616348]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.6069048], dtype=float32)&gt;]\n\n\n\n# 방법 1\nyhat = x * 2.2616348 + 0.6069048 # 최적화 공식\n# 방법 2\nyhat = net.predict(x)\n\n\nplt.plot(x,y,'.')\nplt.plot(x,yhat,'--')\n\n\n\n\n\n\n\n\n- 실패: 이 모형은 epoch을 10억번 돌려도 실패할 모형임 - 왜? 아키텍처 설계자체가 틀렸음 - 꺽인부분을 표현하기에는 아키텍처의 표현력이 너무 부족하다 -&gt; under fit의 문제\n\n\n풀이2: 비선형 활성화 함수의 도입\n- 여기에서 비선형 활성화 함수는 relu\n- 네트워크를 아래와 같이 수정하자.\n(수정전) hat은 생략\n\n#collapse\ngv('''\n\"x\" -&gt; \"x*w,    bias=True\"[label=\"*w\"] ;\n\"x*w,    bias=True\" -&gt; \"y\"[label=\"indentity\"] ''')\n\n\n\n\n\n\n\n\n(수정후) hat은 생략\n\n#collapse\ngv('''\n\"x\" -&gt; \"x*w,    bias=True\"[label=\"*w\"] ;\n\"x*w,    bias=True\" -&gt; \"y\"[label=\"relu\"] ''')\n\n\n\n\n\n\n\n\n\n마지막에 \\(f(x)=x\\) 라는 함수대신에 relu를 취하는 것으로 구조를 약간 변경 = 활성화함수(acitivation function)를 indentity에서 relu로 변경\n활성화함수 : Sigmoid, Hyperbolic Tangent Function 등이 보편적이지만, 기울기소실 문제 발생\n\n→ 가중치 갱신을 위해 전달되는 기울기가 0에 수렴하여 학습이 전혀 되지 않은 상태 즉, 작은 기울기로 인해 가중치가 매우 조금만 업데이트되므로 학습 속도가 느려짐\n- relu함수란?\n\n_x = np.linspace(-1,1,100)\ntf.nn.relu(_x)\n\n&lt;tf.Tensor: shape=(100,), dtype=float64, numpy=\narray([0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.01010101, 0.03030303, 0.05050505, 0.07070707, 0.09090909,\n       0.11111111, 0.13131313, 0.15151515, 0.17171717, 0.19191919,\n       0.21212121, 0.23232323, 0.25252525, 0.27272727, 0.29292929,\n       0.31313131, 0.33333333, 0.35353535, 0.37373737, 0.39393939,\n       0.41414141, 0.43434343, 0.45454545, 0.47474747, 0.49494949,\n       0.51515152, 0.53535354, 0.55555556, 0.57575758, 0.5959596 ,\n       0.61616162, 0.63636364, 0.65656566, 0.67676768, 0.6969697 ,\n       0.71717172, 0.73737374, 0.75757576, 0.77777778, 0.7979798 ,\n       0.81818182, 0.83838384, 0.85858586, 0.87878788, 0.8989899 ,\n       0.91919192, 0.93939394, 0.95959596, 0.97979798, 1.        ])&gt;\n\n\n\nplt.plot(_x,_x)\nplt.plot(_x,tf.nn.relu(_x))\n\n\n\n\n\n\n\n\n\n파란색을 주황색으로 바꿔주는 것이 Relu함수임\n\\(f(x)=\\max(0,x)=\\begin{cases} 0 & x\\leq 0 \\\\ x & x&gt;0 \\end{cases}\\)\n\n- 아키텍처: \\(\\hat{y}_i=relu(\\hat{w}_0+\\hat{w}_1x_i)\\), \\(relu(x)=\\max(0,x)\\)\n- 풀이시작\n1단계\n\nnet2 = tf.keras.Sequential() \n\n2단계\n\ntf.random.set_seed(43053) # 초기값 고정\nl1 = tf.keras.layers.Dense(1, input_shape=(1,)) \na1 = tf.keras.layers.Activation(tf.nn.relu) \n\n\nnet2.add(l1)\n\n\nnet2.layers\n\n[&lt;keras.layers.core.dense.Dense at 0x7f3b5c6e74f0&gt;]\n\n\n\nnet2.add(a1)\n\n\nnet2.layers\n\n[&lt;keras.layers.core.dense.Dense at 0x7f3b5c6e74f0&gt;,\n &lt;keras.layers.core.activation.Activation at 0x7f3aa99a0ee0&gt;]\n\n\n\nl1.get_weights()\n\n[array([[0.41721308]], dtype=float32), array([0.], dtype=float32)]\n\n\n\nnet2.get_weights()\n\n[array([[0.41721308]], dtype=float32), array([0.], dtype=float32)]\n\n\n(네트워크 상황 확인)\n\nu1= l1(x)\n#u1= x@l1.weights[0] + l1.weights[1]\n\n\nv1= a1(u1)\n#v1= tf.nn.relu(u1) \n\n\nplt.plot(x,x)\nplt.plot(x,u1,'--r')\nplt.plot(x,v1,'--b')\n\n\n\n\n\n\n\n\n3단계\n\nnet2.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')  #optimizer = 'sgd'로 설정 가능, but 학습률이 0.01로 자동으로 설정됨\n\n4단계\n\nnet2.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n&lt;keras.callbacks.History at 0x7f3aa9885990&gt;\n\n\n- result\n\n# 모두 동일한 결과 도출 \nyhat = tf.nn.relu(x@l1.weights[0] + l1.weights[1]) # 공식 활용\nyhat = net2.predict(x)\nyhat = net2(x)\nyhat = a1(l1(x))\nyhat = net2.layers[1](net2.layers[0](x))\n\n\nplt.plot(x,y,'.')\nplt.plot(x,yhat,'--')\n\n\n\n\n\n\n\n\n- discussion - 이것 역시 수백억번 에폭을 반복해도 이 이상 적합이 힘들다 \\(\\to\\) 모형의 표현력이 떨어진다. - 해결책: 주황색점선이 2개 있다면 어떨까?\n\n\n풀이3: 노드수추가 + 레이어추가\n목표: 2개의 주황색 점선을 만들자. = 새로운 네트워크 생성\n1단계\n\nnet3 = tf.keras.Sequential()\n\n2단계\n\ntf.random.set_seed(43053)\nl1 = tf.keras.layers.Dense(2,input_shape=(1,)) # 출력값 2개 설정\na1 = tf.keras.layers.Activation(tf.nn.relu)\n\n\nnet3.add(l1)\nnet3.add(a1) \n\n# net3.layers\n\n(네트워크 상황 확인)\n\nl1(x).shape\n# l1(x) : (100,1) -&gt; (100,2) \n\nTensorShape([100, 2])\n\n\n\nplt.plot(x,x)\nplt.plot(x,l1(x),'--')\n# plt.plot(x,l1(x)[:,0],'--')\n# plt.plot(x,l1(x)[:,1],'--')\n\n\n\n\n\n\n\n\n\nplt.plot(x,x)\nplt.plot(x,a1(l1(x)),'--') #relu를 적용했을 경우\n\n\n\n\n\n\n\n\n- 이 상태에서는 yhat이 안나온다. 왜? - 차원이 안맞음. a1(l1(x))의 차원은 (N,2)인데 최종적인 yhat의 차원은 (N,1)이어야 함. → 회귀 문제의 경우, 하나의 예측값을 가져야 하므로 - 차원이 어찌저찌 맞다고 쳐도 relu를 통과하면 항상 yhat&gt;0 임. 따라서 음수값을 가지는 y는 0으로 밖에 맞출 수 없음.\n- 해결책: a1(l1(x))에 연속으로(Sequential하게!:순서에 맞게) 또 다른 레이어를 설계! (N,2) -&gt; (N,1) 이 되도록! - yhat= bias + weight1 * a1(l1(x))[0] + weight2 * a1(l1(x))[1]\n- 즉 a1(l1(x)) 를 새로운 입력으로 해석하고 출력을 만들어주는 선형모형을 다시태우면 된다. - 입력차원: 2 - 출력차원: 1\n\nnet3.layers\n\n[&lt;keras.layers.core.dense.Dense at 0x7f3aa62bb3d0&gt;,\n &lt;keras.layers.core.activation.Activation at 0x7f3aa62baad0&gt;]\n\n\n\ntf.random.set_seed(43053) \nl2 = tf.keras.layers.Dense(1, input_shape=(2,))\n\n\nnet3.add(l2) \n\n\nnet3.layers\n\n[&lt;keras.layers.core.dense.Dense at 0x7f3aa62bb3d0&gt;,\n &lt;keras.layers.core.activation.Activation at 0x7f3aa62baad0&gt;,\n &lt;keras.layers.core.dense.Dense at 0x7f3aa61c3160&gt;]\n\n\n\nnet3.summary()\n\nModel: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_10 (Dense)            (None, 2)                 4         \n                                                                 \n activation_9 (Activation)   (None, 2)                 0         \n                                                                 \n dense_11 (Dense)            (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 7\nTrainable params: 7\nNon-trainable params: 0\n_________________________________________________________________\n\n\n-net3 모델은 2개의 은닉층을 가짐\n- 추정해야할 파라메터수가 4,0,3으로 나온다.\n- 수식표현: \\(X \\to X@W^{(1)}+b^{(1)} \\to relu(X@W^{(1)}+b^{(1)}) \\to relu(X@W^{(1)}+b^{(1)})@W^{(2)}+b^{(2)}=yhat\\)\n\n입력 데이터(입력층) → 가중치 행렬과 편향벡터를 사용하여 선형 변환 → 은닉층에 비선현성 추가 → 모델의 예측값\n\n\n\n\nimage.png\n\n\n- 참고: 추정할 파라메터수가 많다 = 복잡한 모형이다. - 초거대AI: 추정할 파라메터수가 엄청 많은..\n\nnet3.weights\n\n[&lt;tf.Variable 'dense_10/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 0.34065306, -0.7533803 ]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_10/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 0.34065306],\n        [-0.7533803 ]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&gt;]\n\n\n\nl1.weights\n\n[&lt;tf.Variable 'dense_10/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 0.34065306, -0.7533803 ]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_10/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)&gt;]\n\n\n\nl2.weights\n\n[&lt;tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 0.34065306],\n        [-0.7533803 ]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&gt;]\n\n\n- 좀 더 간단한 수식표현: \\(X \\to (u_1 \\to v_1) \\to (u_2 \\to v_2) = yhat\\) - \\(u_1= X@W^{(1)}+b^{(1)}\\) # 선형변환 - \\(v_1= relu(u_1)\\) # 활성화 함수 - \\(u_2= v_1@W^{(2)}+b^{(2)}\\) # 선형변환 - \\(v_2= indentity(u_2):=yhat\\) # 활성화 함수\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"u1[:,0]\"[label=\"*W1[0,0]\"]\n    \"X\" -&gt; \"u1[:,1]\"[label=\"*W1[0,1]\"]\n    \"u1[:,0]\" -&gt; \"v1[:,0]\"[label=\"relu\"]\n    \"u1[:,1]\" -&gt; \"v1[:,1]\"[label=\"relu\"]\n    label = \"Layer 1\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"v1[:,0]\" -&gt; \"yhat\"[label=\"*W2[0,0]\"]\n    \"v1[:,1]\" -&gt; \"yhat\"[label=\"*W2[1,0]\"]\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\n\n\n\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"node1\"\n    \"X\" -&gt; \"node2\"\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"yhat\"\n    \"node2\" -&gt; \"yhat\"\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\n\n\n\n3단계\n\nnet3.compile(loss='mse',optimizer=tf.optimizers.SGD(0.1))\n\n4단계\n\nnet3.fit(x,y,epochs=1000,verbose=0, batch_size=N) \n\n&lt;keras.callbacks.History at 0x7f3aa61ba560&gt;\n\n\n- 결과확인\n\nnet3.weights\n\n[&lt;tf.Variable 'dense_10/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 1.6352799 , -0.85507524]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_10/bias:0' shape=(2,) dtype=float32, numpy=array([-0.08284465,  0.85552216], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 1.6328746],\n        [-1.2001747]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([1.0253307], dtype=float32)&gt;]\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,net3(x),'--')\n\n\n\n\n\n\n\n\n- 분석\n\nplt.plot(x,y,'.') \nplt.plot(x,l1(x),'--')\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,a1(l1(x)),'--')\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,l2(a1(l1(x))),'--')\n\n\n\n\n\n\n\n\n- 마지막 2개의 그림을 분석\n\nl2.weights\n\n[&lt;tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 1.6328746],\n        [-1.2001747]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([1.0253307], dtype=float32)&gt;]\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \nfig.set_figwidth(12) \nax1.plot(x,y,'.')\nax1.plot(x,a1(l1(x))[:,0],'--r')\nax1.plot(x,a1(l1(x))[:,1],'--b')\nax2.plot(x,y,'.')\nax2.plot(x,a1(l1(x))[:,0]*1.6328746,'--r')\nax2.plot(x,a1(l1(x))[:,1]*(-1.2001747)+1.0253307,'--b')\nax3.plot(x,y,'.')\nax3.plot(x,a1(l1(x))[:,0]*1.6328746+a1(l1(x))[:,1]*(-1.2001747)+1.0253307,'--')\n\n\n\n\n\n\n\n\n\n\n\n풀이3의 실패\n\ntf.random.set_seed(43054) \n## 1단계\nnet3 = tf.keras.Sequential() \n## 2단계\nnet3.add(tf.keras.layers.Dense(2))\nnet3.add(tf.keras.layers.Activation('relu')) \nnet3.add(tf.keras.layers.Dense(1))\n## 3단계 \nnet3.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\n## 4단계 \nnet3.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n&lt;keras.callbacks.History at 0x7f3a70c237c0&gt;\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,net3(x),'--')\n\n\n\n\n\n\n\n\n- 엥? 에폭이 부족한가?\n\nnet3.fit(x,y,epochs=10000,verbose=0,batch_size=N)\nplt.plot(x,y,'.')\nplt.plot(x,net3(x),'--')\n\n\n\n\n\n\n\n\n- 실패분석\n\nl1,a1,l2 = net3.layers\n\n\nl2.weights\n\n[&lt;tf.Variable 'dense_13/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[0.65121335],\n        [1.8592643 ]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([-0.60076195], dtype=float32)&gt;]\n\n\n\nfig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) \nfig.set_figwidth(16) \nax1.plot(x,y,'.')\nax1.plot(x,l1(x)[:,0],'--r')\nax1.plot(x,l1(x)[:,1],'--b')\nax2.plot(x,y,'.')\nax2.plot(x,a1(l1(x))[:,0],'--r')\nax2.plot(x,a1(l1(x))[:,1],'--b')\nax3.plot(x,y,'.')\nax3.plot(x,a1(l1(x))[:,0]*0.65121335,'--r')\nax3.plot(x,a1(l1(x))[:,1]*(1.8592643)+(-0.60076195),'--b')\nax4.plot(x,y,'.')\nax4.plot(x,a1(l1(x))[:,0]*0.65121335+a1(l1(x))[:,1]*(1.8592643)+(-0.60076195),'--')\n\n\n\n\n\n\n\n\n\n보니까 빨간색선이 하는 역할을 없음\n그런데 생각해보니까 이 상황에서는 빨간색선이 할수 있는 일이 별로 없음\n왜? 지금은 나름 파란색선에 의해서 최적화가 된 상태임 \\(\\to\\) 빨간선이 뭔가 하려고하면 최적화된 상태가 깨질 수 있음 (loss 증가)\n즉 이 상황 자체가 나름 최적회된 상태이다. 이러한 현상을 “global minimum을 찾지 못하고 local minimum에 빠졌다”라고 표현한다.\n\n확인:\n\nnet3.weights\n\n[&lt;tf.Variable 'dense_12/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[-0.03077251,  1.8713338 ]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_12/bias:0' shape=(2,) dtype=float32, numpy=array([-0.04834982,  0.3259186 ], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_13/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[0.65121335],\n        [1.8592643 ]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([-0.60076195], dtype=float32)&gt;]\n\n\n\n# 데이터 직접 선언해보기\nW1= tf.Variable(tnp.array([[-0.03077251,  1.8713338 ]]))\nb1= tf.Variable(tnp.array([-0.04834982,  0.3259186 ]))\nW2= tf.Variable(tnp.array([[0.65121335],[1.8592643 ]]))\nb2= tf.Variable(tnp.array([-0.60076195])) \n\n\n# MSE 활용하여 손실 계산\nwith tf.GradientTape() as tape: \n    u = tf.constant(x) @ W1 + b1 \n    v = tf.nn.relu(u) \n    yhat = v@W2 + b2 \n    loss = tf.losses.mse(y,yhat) \n\n\n# 기울기 계산\ntape.gradient(loss,[W1,b1,W2,b2])\n\n[&lt;tf.Tensor: shape=(1, 2), dtype=float64, numpy=array([[ 0.00000000e+00, -4.77330119e-05]])&gt;,\n &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.0000000e+00, 3.1478608e-06])&gt;,\n &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n array([[ 0.00000000e+00],\n        [-4.74910706e-05]])&gt;,\n &lt;tf.Tensor: shape=(1,), dtype=float64, numpy=array([-2.43031263e-05])&gt;]\n\n\n예상대로 계수값이 거의 다 0이다. (수렴문제?)\n\n최적화(Optimizer) 종류\n\n\n\n\n\n# Momentum GD 적용해보기\n# 기울기 0을 탈출하지 못한다는 것은 훈련이 느리다는 것 -&gt; 관성을 적용하여 변수가 가던 방향에 속도항을 추가함\n# 모델 정의\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(1, input_shape=(1,))\n])\n\n# 손실 함수 정의 (평균 제곱 오차)\ndef custom_loss(y_true, y_pred):\n    return tf.reduce_mean(tf.square(y_true - y_pred))\n\n# Momentum 옵티마이저 생성\nlearning_rate = 0.1\nmomentum = 0.9\noptimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n\n# 모델 컴파일\nmodel.compile(optimizer=optimizer, loss=custom_loss)\n\n# 모델 훈련\nepochs = 1000\nmodel.fit(x, y, epochs=epochs, verbose=0)\n\n# 훈련된 모델을 사용하여 예측\ny_pred = model.predict(x)\n\n# 결과 확인\nprint(\"Predicted:\")\nprint(y_pred[:5])\nprint(\"Actual:\")\nprint(y[:5])\n\n\nwith tf.GradientTape() as tape:\n    # 손실 함수 계산\n    loss = custom_loss(y, model(x))\n\n# 기울기 계산\ngradients = tape.gradient(loss, model.trainable_variables)\n\n# 기울기 출력\nfor var, grad in zip(model.trainable_variables, gradients):\n    print(f'Variable: {var.name}, Gradient: {grad.numpy()}')\n\n\n\n풀이4: 노드수를 더 추가한다면?\n- 노드수를 더 추가해보면 어떻게 될까? (주황색 점선이 더 여러개 있다면?)\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"node1\"\n    \"X\" -&gt; \"node2\"\n    \"X\" -&gt; \"...\"\n    \"X\" -&gt; \"node512\"\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"yhat\"\n    \"node2\" -&gt; \"yhat\"\n    \"...\" -&gt; \"yhat\"\n    \"node512\" -&gt; \"yhat\"\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\n\n\n\n\ntf.random.set_seed(43056)\nnet4= tf.keras.Sequential()\nnet4.add(tf.keras.layers.Dense(512,activation='relu')) # 이렇게 해도됩니다. \nnet4.add(tf.keras.layers.Dense(1))         \nnet4.compile(loss='mse',optimizer=tf.optimizers.SGD(0.1)) \nnet4.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n&lt;keras.callbacks.History at 0x7f34ac815d20&gt;\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,net4(x),'--')\n\n\n\n\n\n\n\n\n\n잘된다..\n한두개의 노드가 역할을 못해도 다른노드들이 잘 보완해주는듯!\n\n- 노드수가 많으면 무조건 좋다? -&gt; 대부분 나쁘지 않음. 그런데 종종 맞추지 말아야할것도 맞춤.. 즉, 노이즈값도 학습할 수 있다..(overfit)\n\nnp.random.seed(43052)\nN=100 \n_x = np.linspace(0,1,N).reshape(N,1) \n_y = np.random.normal(loc=0,scale=0.001,size=(N,1))\nplt.plot(_x,_y)\n\n\n\n\n\n\n\n\n\ntf.random.set_seed(43052) \nnet4 = tf.keras.Sequential()\nnet4.add(tf.keras.layers.Dense(512,activation='relu'))\nnet4.add(tf.keras.layers.Dense(1))\nnet4.compile(loss='mse',optimizer=tf.optimizers.SGD(0.5))\nnet4.fit(_x,_y,epochs=1000,verbose=0,batch_size=N)\n\n&lt;keras.callbacks.History at 0x7f34ac2f3640&gt;\n\n\n\nplt.plot(_x,_y)\nplt.plot(_x,net4(_x),'--')\n\n\n\n\n\n\n\n\n\n이 예제는 추후 다시 공부할 예정\n\n\n\n\nLogistic regression\n\nmotive\n- 현실에서 이런 경우가 많음 - \\(x\\)가 커질수록 (혹은 작아질수록) 성공확률이 올라간다.\n- 이러한 모형은 아래와 같이 설계할 수 있음 &lt;– 외우세요!! - \\(y_i \\sim Ber(\\pi_i)\\), where \\(\\pi_i=\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\n\\(\\hat{y}_i =\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) → 실제 레이블(y)이 1일 때, 모델이 1을 예측한 경우의 로그 손실 + 실제 레이블(y)이 0일 때, 모델이 0을 예측한 경우의 로그 손실\n\n- 위와 같은 손실함수를 BCEloss라고 부른다. (BCE는 Binary Cross Entropy의 약자)\n\nCrossEntropyLoss 함수\n\n\n\n\n→ 클래스가 2개인 binary case 인 경우, BCEloss 사용\n\n\n예제\n\nN = 2000 \n\n\nx = tnp.linspace(-1,1,N).reshape(N,1)\nw0 = -1 \nw1 = 5 \nu = w0 + x*w1 \n#v = tf.constant(np.exp(u)/(1+np.exp(u))) # v=πi \nv = tf.nn.sigmoid(u) \ny = tf.constant(np.random.binomial(1,v),dtype=tf.float64) \n\n\nplt.plot(x,y,'.',alpha=0.02)\nplt.plot(x,v,'--r')\n\n\n\n\n\n\n\n\n- 이 아키텍처(yhat을 얻어내는 과정)를 다어어그램으로 나타내면 아래와 같다.\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x\" -&gt; \"x*w, bias=True\"[label=\"*w\"]\n    \"x*w, bias=True\" -&gt; \"yhat\"[label=\"sigmoid\"]\n    label = \"Layer 1\"\n}\n''')\n\n\n\n\n\n\n\n\n- 또는 간단하게 아래와 같이 쓸 수 있다.\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    x\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    x -&gt; \"node1=yhat\"\n    label = \"Layer 1: sigmoid\"\n}\n''')\n\n\n\n\n\n\n\n\n- 케라스를 이용하여 적합을 해보면\n\n\\(loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\n\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential() \nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nbceloss_fn = lambda y,yhat: -tf.reduce_mean(y*tnp.log(yhat) + (1-y)*tnp.log(1-yhat))\nnet.compile(loss=bceloss_fn, optimizer=tf.optimizers.SGD(0.1))\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n&lt;keras.callbacks.History at 0x7f349c638670&gt;\n\n\n\nnet.weights\n\n[&lt;tf.Variable 'dense_28/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[4.1423755]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense_28/bias:0' shape=(1,) dtype=float32, numpy=array([-0.820938], dtype=float32)&gt;]\n\n\n\n# BCEWithLogitsLoss 함수 활용 : 만약 Sigmoid를 사용한다면, 활성화 함수 활용하지 않고 출력값에 적용하는 BCEWithLogitsLoss를 사용하는 것이 더 안정적\ntf.random.set_seed(43052)\nnet2 = tf.keras.Sequential()\nnet2.add(tf.keras.layers.Dense(1,))\nbce_logits_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nnet2.compile(loss=bce_logits_loss, optimizer=tf.optimizers.SGD(0.1))\nnet2.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n\nnet2.weights\n\n\nplt.plot(x,y,'.',alpha=0.1)\nplt.plot(x,v,'--r')\nplt.plot(x,net(x),'--b')\n\n\n\n\n\n\n\n\n\n\nMSE loss?\n- mse loss를 쓰면 왜 안되는지?\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential() \nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nmseloss_fn = lambda y,yhat: tf.reduce_mean((y-yhat)**2)\nnet.compile(loss=mseloss_fn, optimizer=tf.optimizers.SGD(0.1))\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n&lt;keras.callbacks.History at 0x7f349df8cc10&gt;\n\n\n\nplt.plot(x,y,'.',alpha=0.1)\nplt.plot(x,v,'--r')\nplt.plot(x,net(x),'--b')\n\n\n\n\n\n\n\n\n\n일단 BCE loss와 비교해보니까 동일 초기값, 동일 epochs에서 적합이 별로임\n\n\n\nMSE loss vs BCE loss\n- MSEloss, BCEloss의 시각화\n\nw0, w1 = np.meshgrid(np.arange(-10,3,0.2), np.arange(-1,10,0.2), indexing='ij')\nw0, w1 = w0.reshape(-1), w1.reshape(-1)\n\ndef loss_fn1(w0,w1):\n    u = w0+w1*x \n    yhat = np.exp(u)/(np.exp(u)+1)\n    return mseloss_fn(y,yhat) \n\ndef loss_fn2(w0,w1):\n    u = w0+w1*x \n    yhat = np.exp(u)/(np.exp(u)+1)\n    return bceloss_fn(y,yhat) \n\nloss1 = list(map(loss_fn1,w0,w1))\nloss2 = list(map(loss_fn2,w0,w1))\n\n\nfig = plt.figure()\nfig.set_figwidth(9)\nfig.set_figheight(9)\nax1=fig.add_subplot(1,2,1,projection='3d')\nax2=fig.add_subplot(1,2,2,projection='3d')\nax1.elev=15\nax2.elev=15\nax1.azim=75\nax2.azim=75\nax1.scatter(w0,w1,loss1,s=0.1)\nax2.scatter(w0,w1,loss2,s=0.1) \n\n\n\n\n\n\n\n\n\n왼쪽곡면(MSEloss)보다 오른쪽곡면(BCEloss)이 좀더 예쁘게 생김 -&gt; 오른쪽 곡면에서 더 학습이 잘될것 같음\n\n- discussion - mse_loss는 경우에 따라서 엄청 수렴속도가 느릴수도 있음. - 근본적인 문제점: mse_loss일 경우 loss function의 곡면이 예쁘지 않음. (전문용어로 convex가 아니라고 말함) - 좋은 옵티마이저를 이용하면 mse_loss일 경우에도 수렴속도를 올릴 수 있음 (학습과정 시각화예시2). 그렇지만 이는 근본적인 해결책은 아님. (학습과정 시각화예시3)\n- 요약: 왜 logistic regression에서 mse loss를 쓰면 안되는가? - mse loss를 사용하면 손실함수가 convex하지 않으니까! - 그리고 bce loss를 사용하면 손실함수가 convex하니까!",
    "crumbs": [
      "Lecture",
      "Posts",
      "Study",
      "06. net 설계 (2)"
    ]
  }
]